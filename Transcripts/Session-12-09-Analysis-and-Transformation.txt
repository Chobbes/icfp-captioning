>> The next speaker, presenting generating circumstances with generators. Today I'm talking about generating circuits with generators, and first would like to motivate my choice. And why so recently, John L Hemnessy.
In the next decade, the Cambrian explosion... and so functional programming. And said that, the PL community standeds on the critical path to the new golden age computer architecture, FOFRJ FOFRJly, there is addone dance of intellectual challenges that are on the cusp of a new golden age different languages. So it looks like there are things to be done here. So there are some things that are motivating me personally. So one thing is open source sites. So for a long time. How was development tools were closed. And more and more tools, and so that's great. And another thing motivating me is RISC-V, open CPU architecture development at Berkeley bowfin in academia and in industry and.
Everyone loves it. Good motivation I think. Another thing, is FPGA's, the things that are kind of PCU's, interpret circuits.
And domain specific acceleration in the cloud.
So do some stuff for you.
So what is... digital circuit exactly. Some of you network of image of gates, and very low nodal. And take a high level approach. Of mini machines.
And this state changes from one to another. And discrete, and have two functions. One transition functions. And one that says... another output functions, what is the out put of circuit in current cycle.
Show you a few examples. Andstores the current value of the counter and then the other, which can increment the counter.
So the value of the counter trend cycle when the input is one, so we can with one d that one can be exploited bee localment.
And clearly see the transition function, and our function in this. And another variant of the counter. This... output depends on the site. No it stayed only in the next clock cycle. After the input, so, we see that in the first clock cycle. Implemented only in the second cycle.
So the last example I want to show you is one with counter flow, so you can traditionally express control flow in mini machines as state diagrams, and on the edges are the conditions, which show you, which conditions you change the current state.
So this kind of looks like flow truss. And program doesn't really use flow truss, any more.
Using... kind of looks like...
So what we really like to do is have some structural way to describe control flow.
. And this is what I decided to do. I developed programming language, and it's a language for describing automata of course. Its embedded in clash program. Cluster for hi bred.
Hybred. And also can be compiled.
I use Haskle, l. It is a...
can be embedded in a way. And another feature is... this tax is unbeded essentially. But, amount of state in machine is constant rate.
Okay. Core feature of this language. Yield statement, generic abstraction. Generates, and simultaneous l, and bvances the clock so that the next statements are using the input values from the next clock cycle. Let's go back to what I was showing before Right, so this example for circuit. And we see that each described, we have this variable, which stores the current value of the counter or loop, which runs forever. And we have statements inside the loop, the assignment will commence the call to this extent, we extend, one value, and then we change the value.
For example, if their input. Is the next output.
And... in the Moore, version.
It's a little bit more involved.
We need to yield the value which was in the state of the current cycle. But at the point, I do the weed of, or the next climate cycling.
Clear we are already in the next clock cycle, Given the semantic segment, right, so we need to access the value of the input from before the yield so we start using this statement here, and this part that will turns out is very useful language, so I added sugar following this.
So this is value of I before the yield.
So in this way, we don't need to use this let any more.
So last example, with control flow. And here we see normal structure way to describe. No longer a big switch statement.
Right?
So first loping is using continue statement. Another on until. And use magic prime. As in the same cycle. Before the yield.
And after those two loops, we had which is corresponds at the bottom, and then we need to go back to the start so is this. , so we see that this control flow and many other useful invoice of control flow can be easily described.
How this language works. And get number of transformation.
And eliminates loops, and have Lambda lifting, that makes all the functions... they have normalization which stands for almost a normal form. And in the multiple variables.
And here, the implicit replaced by explicit using data types, and next transition, makes that each function yields exactly once before making tail call so the functions can correspond 1 to 1, to states or group of states. And cleans up the code, and then when we have group of functions, and each exactly once, can mediate after that.
Ands here an example how that works. And you can read in the paper. Here we see how that works for mini counter, you have one function, and increments, the value, the mow variations as we see the as we see it yields the value which was the parameter, but course, or if the income and value. And last example, from counter flow, compiles. It's easy to see recursive functions that use if statements to select which function is the next state.
Okay. So... now it's time to see some applications.
So this is how language develops. How does it impact.
Can we do something with it?
So first example pretty simple.
Display. Probably know them.
HDA 4478200. If never programmed them. Before you start writing to them you need to initialize them there is a sequence of commands which needs to be timed exactly to initialize the displays on the after them. Often initialization, you can work with them m. So, normally you will have them using microcontrollers. And it's easy, if you try different languages it's complex.
So I SFOUPD imply LEMation called open hours I tried to implement this time, using... so my implementation, only 149 Were only 40 code lines of yield FSM, and that has those helper definition, and 26 blocks, that look like this, describes all the things to timing, and counting amount of timing for each command to output thes that happen on operations, and so on, so it's not easy to read, write, and not anything you want to work with.
And when you use, FSM becomes something like this..
And path is here. So this initial sequence is first 8 calls and cools and delay.
First arguments is amount of mille seconds to wait. Is second, because the display was giving data, and last argument is instruction we send. And thanks, to... pretty incredible.
And just wait or commands in the on the bus, and when the command that is we just send it to the days play. Display.
Obviously, implement risk five processor and implemented not one but three of them, or three of them are multi cycle. Like textbook one. And first one, not complicated. And the same data process before.
And the last one, youthe most experimental one, where I imprinted the whole multigrid processor using either the FSM.
.
So replacing control path. And keeping the same performance, as before.
The implementation. Quite a lot smaller. And some performance loss.
And didn't yet find the reason for that. Still open question why that happened. So the conclusions we can compare can compile structural procedure, and conclusions.
We can compile structural procedural content without data.
I think that that's right. So now we can write things like this in much more readable and maintainable way. And we didn't lose expressivity in development right so we can all the things we could do in verilog or VHDL, we can still do. The code in the language is shorter. And lowers the barrier to enter.
Okay, so some work I like to do later. And functions, for this.
And this is first of the functions I like to do simple.
And because, you have this kind of of effect, look if there this can be generalized in some way.
And that's all, thank you.
[Applause]
>> Questions?
>> So as I understand it the benefit you gave of the example over here.
>> When you speak to the mike don't know where it's coming from.
>> The example that you gave, I think I understand it to benefit from the fact that VHDL and Verilog doesn't have Lambda abstractions.
So, you know; you use Lambda abstraction to reduce the lines of code. More pertinent to FP understand more merely automata to compose very rich ways. Have you looked at algebra, of automata. I try to think a little about this, but I didn't really something which I I just decided to make the to allow a combining the automata just using clash as as this language for for for expressing connections in them so we can you big problem you want to solve you can you can encode into a series of simpler, smaller automata . Each of those you can you can write using, and then connect them together using crash.
>> Question over here.
>> Okay.
>> Just want to clarify what you meant by multicycle processer. Does that mean multipsychoermultipsychoer that mean it takes multiple cycles per instruction?
And yes, there's only one going at once. So it's not your classic kind of optimized processor. Is your language going to be useful for say pipelines processors in it useful for pipeline processors .
>> Because actually pipe pipe and or conflicted quite differently. This language. The whole idea was to implement control flow in some way, right.
And pipelines are not really about control flow about data floww. So not a language for pipelines.
>> So should use for relative simple state machines that are in some sense. Simple enough, they don't need all the complexities of VHDL. Is that the right way? To think about itt?
>> Probably yes.
>> One of the transformation, you mentioned, was eliminating nontail recursive calls.
>> Could you expand on are.
>> Again, which one you call stack? Reification reification.
So this is one of the most this paper, because what I'm doing there is some kind of combined de functionalisation and continuity ... I couldn't use normal ways to do it. With template Haskell. And they get passed. Over. Which is typed.
Have a different continuation for every type. Had to use another apreach. Use Some approach I taken was that I use control flow information to generate many different data types for each, for each strongly connected component .
>> One more question. So on the driver example, you said that it's 270VHDL. Versus 150 lines, versus clash. How does it compare with just clash.
Using clashes tooling of abstraction to their fullest.
>> I will answer this question, traditional implementation is in clash.
>> That can mean many different things, wiring together, and you are using like custom data types to manage your state etc So, is this comparing like high level clash or low level crash.
I tried to be somewhere the in the middle. Too involved in this amount of but, still don't want it to look like for workingg. So this is the.
>> Thank you, let's take the rest of the discussion offline, thank you, again [applause]
>> And then the next speaker talking about stage compilation with two level type theory.
>> Enter presentation mode.
>> Hello, everyone, this is going to be a talk about stage compilation for two level type theory Y stage compilation,
Writing code generating code good ergonomics and safety guarantees. And there are many examples for the existing infrastructure like this. We have typed template Haskell or the template Haskell, we have C++ templates we have traits macros and generics in rust, and in all of these cases there is a separation between what is the compile time language and what is the runtime language. In all these cases I think points to improve ergonomics and safety guarantees as well. So part of this talk is about how to do better than these systems in certain ways.
And what are motivation for using... one is low-cost, I'm saying low-cost, instead of zero cost. Because, in terms of code size when they are using sage compilation. However, I think in many situations it is get a moderate increase insize, but also get like large increase in performance. And I really like like the usual abstractions, developed in fact functional programming. And I would also like to. ... make the cost of these abstractions lower. And also domain specific languages. And this is quite important, I think most of the large performance gains, come from domain specific insights.
And it's not really feasible to have general purpose optimization in some compiler, that knows all about the insights. So make it possible for programmers to KEECH compilerses, and also, there is inlining and fusion with strong GRARN tees.
I have worked a lot, the writing high performance, Haskell code, and frustrating have fragile infrastructure, for inlining and FUNGS optimizations.
It's much more infrastructure... that for example, fusion happens and goes through. What is two level theory. First the idea was developed by Voevodsky. And idea was to do modular treatment for axioms, and two level type theory. And interestingly here.
The title says applications, but stage compilation is not mentioned at all. All applications... it turns out the system is applicable to two...
so, if punishes ood example for like a cross pollination of very distant fields. So what is the features, so there's an integration of a compact and language in the runtime, language, and there's also guarantee think of code output and also guarantee that staging and by vacillating I mean that in the, in the generated code there are no meta programming features anymore, which are, which live in the in the macro stage. And SUCHTs wide range of runtime and metalanguages. O here we can make a choice so we can make the two languages very similar, but we can also choose to make certain advantages here.
And have independent times, in metalanguage, and object language, so that's what I choose to develop in this paper.
So the setting, and also support the present, staging by evaluation. So this is analogous to normalization by evaluation in the sense that we are evaluating a stage program into a semantic domain, and then we are extracting decoder output from this multi domain. So this talk contains small programming examples, for tutorial example can see the artifact, and implementation of this, and samples, from go, and you can see the paper.
And basic rules, two universes.
And closed under type of... the universe of run it is time types, and you have something, will appear...
If you have some type in... it can not appear in the staging, because it happens to live only in the in the compile time language and during staging it has to disappear at some point.
It has to be consulted away.
Okay. And likewise if you have an inhabitant of some compile time type than that inhabitants value also cannot appear in the staging out put. And all in the same universe. No way to cross universes at all. Only way to cross the two universe is by SPAFK staging operations. So listing, if you have runtime type. And this up arrow A, and means type of metto programs, generating code with type A. So in other systems could be called code of A. And called. So instead of upper, called code, or X. So we have quoting. If you have any runtime value, and any runtime expression, you can quote it, and it's just a metaprogram that immediately returns that expression. And have splicing, so metaprogram that has slices.
Essentiallies f PSns that during staging smarter program will be executed and then decode result will be inserted into, into the output.
And we also have this to definition of inequalities. So quoting and splicing, definition of isomorphism And this is important if you want to do polymorphic and dependently type programming because programs will be only aboutto these two roles. And so And then, informally Staging means we are running or meta programs in s[isplices. And then insert the results in the code output.
Okay, so let's look at some more examples. So we can just do inline definition. In this case, the program consists of just two top level definitions. And we have a meta level definition of two which is just a quotation of a sub zero sub zer.
But here run zero.
So here the definition is just a quoted expression, and when defining the function in the runtime language, I can just use a splice. And then when I do the staging, then only the object level bindings remain.
So in case, only have F.
And I perform the splicing.
Okay. Let's look at the compile-time identity function.
So this ID is an ordinary polymorphic identity function, but here I'm using a notation like for a PI type. So if I have any typing new one, this is just a polymorphic identity, but because I have ... , I can use, use these functions in object level code. So in runtime code as well. So here, this is the identity function for Boolean, but I'm doing the splicing, and I'm calling to this metal halide and function, and I'd have to pass the time. And then I have to pass an expression, and the time that I pass is just the lift of ... So because this is the time, then I can pass a quotation of an expression as the next argument and.
And then the output, I can write alternative function.
That is bit more interesting. I say, I want to RUP run...say that I only want to quantify over the runtime types. However, the quantification itself happens in the compile time language. So this a is more like an expression of a runtime time.
And then, it's still the usual identity function. But because this is a lifting of something, it's more like an expression efforts splice it, and then I have to live with back again.
So this demonstration, we have staging and quotation for as well. So see later example, how this has to be used.
And I probably will skip this.
But the point is that this example is only up to the previous mentioned definition, so here I have this type, but actually expect type of this this form. That says, quotation, mispricing or definition isomorphisms and sorry I also mentioned, I should stronger than anything else. So this is kind of borrowed from the, from the meta notation of splicing. If you do staging here, once again, just. So, here the nothing interesting happen, but if we go to a slightly more complicated example for doing the map function inlining then really hear the need to use abstraction over runtime types, because we want to use runtime lists, and as I mentioned before, the only way to grasp between the different stages, is to use lifting and splicing and quotation. Must be a runtime type as an argument, so we can only observe over time facts like this And if you look at the definition of heritability solenoids properly explained in detail. The point is that now we can use the inline map function and if it goes on staging than what we get is essentially this further zero function And we have inline function into this definition.
And this looks.
Might look a bit noisy with all the quotations and splices, and roughly the level of noise, you have to concern yourself with, using Haskell which is quite noise, but in the system can do strong inference for quotes and splices. So before looking at the inference, to note, we have preservation of types.
So listing of a function, and isomorphic definition.
Here this is notation for dependent paradigm is isomorphic to a dependent pair of things.
And we can use these properties, and use bidirectional elaboration, and also the fact we stayed in universes. We do not have the template haske, l.
So here, we can use bidirectal elaboration, and subTIEBing for all the splices, and in the can just become like this. And also implement the artifact demo.
And we can also stage types.
So if incomplete have a natural number. I can by inductionen otheothe almost I'm using.
And you can see that what happens here is that I'm computing Tuple of certain length. How much time do I have 3 minutes. Okay. So, in I lose induction on compile time data, I can compute times, and also use dependentment elimination.
On dependancy types programs, of computed times, and in this case, to define mapping function, have to use DPEMENTent types Northrth stage compilation are quite compelling because one of the one of the use cases one of the important use cases in staging is generic programming.
And although in like normal programming, we can get by without dependent types in generic programming. It's quite common that you really need dependent types, to make a generic program. Okay, so more things, in the artifact, there is implementation stage for the PUGS. And therapeutic fusion type staged SDLC interpreter, and also demonstration of monadic let insertion. And in the paper, that's the formal so in the paper staging these evaluation of level type theory in propitiates over the object theory syntax and correctness of staging is a content activity property and correctness is shown by proof read ontological relations internally to....
>> Thank you.
[Applause]
>> Very nice work. I was wondering how difficult was this to implement compared to a normal dependly type language.
>> Not very difficult. The staging algorithm it is, is even simpler than the normalization by other evaluation that you have to implement for conversion.
Checking. So, yeah, I mean, if you have dependent types you have to do me a conversion, but staging is simpler..
>> Follow-up question, how difficult to add to Agda.
>> Let's discuss many. But the specifics details of... can make it possibly nightmarish.
[Laughter]
>> Thank you very much. Great talk. In the middleal. Yep. I had a quick question. So you showed what it's like to write these staged programs. But what happens if I want to prove something about the stage computation, do I have to prove something about generated code, or is there a way to prove stage itself. You can use the full power of the metal paper...metal level type theory to reason about object level programs, but only up to definitional equality. So, like the bat notion of equality is just to for the object, programs, and it is useful for many things, but it's not really semantic notion of program.
>> So you can observe what the result of the staging will be, but you can't prove by induction that every staged computation is well behaved. You can mov you are on...prove properties about your genetic code inside the system. Thanks very much.
>> You had function identity function earlier, you identified on tape A universe unwith.
Anything that limits you from being stage polymorphic saying saying that it works for some universe you such that the A and the A are still at the same universe level. Es, so this is potential future work. And, but in order to make the sound, you probably need another universe.
E, and then you say that polymorphism over zero and one can be expressed in U2. But this is possible.
>> Any more questions. It wasn't clear to me if there was additional power in the metalanguage. Do you get typecase for example. Do FRM PL ... this is also part of future work. Depends on the general setup. Question is, it could do... analysis of expressions in general So if you have something with type, lift the then you can get a meta program which like matches on the structure of the expression, and then this does something, and it's a complicated question. It's not yet implemented but it's also discussed in the paper, to some extent.
>> Okay. Okay, these were all the questions, thank you again.
[Applause]
>> Last speaker in this session who will be presenting experience report on random testing of higher order blockchain language.
>> ILYA SERGEY: All right, good afternoon, everyone, it's my great pleasure to present our joint work with Tram Hoang, Anton and Leonidas Lampropoulos.
So I'm going to talk about our experiment with applying property based testing to language layer in an industrial grade blockchain system. . And this was an experiment report.
What is the blockchain is a question that I'm not going to answer in this doc, c, if you've been around for the last five years, you could have noticed an explosion of blockchain consensus systems have different levels of expressivity. Or even if your area, whatsoever, but you weren't showing up at ICFP You still know what blockchain is So the question that I'm going to focus on is how do we do programming for blockchain? And what good and bad things can happen o it turns out that if you want to have your functional core imperative code replicated using Blockchain consensus protocol, it's actually pretty easy to join You're just package your code as a module with a state and a function into a model, which is usually called a smart contract, and then you make a proposal to the quorum in the system in the form of a transaction. And before you propose the code to be massively replicated. And diligence, and parser, and do the check in.
And make sure this is the case.
The most important, allocate some of amount of virtual al currency.
Typically associated with the system. Just to compensate all the parties will be replicating the same process of validation, just to double check that you are not proposing something boggles before your code is replicated and propagated to the system, after which every participant in the consensus protocol has a copy of your code. And question how to evolve the state, and use the code already deployeden othe blockchain, that also turns out to be relatively straightforward so one thing that you need to do is to identify the smart contract, the module that you're going to extract with. You're going to go, and then you're going to form a message, which again comes with some money attached to that. All that makes it into transaction, after which this message containing the directives for the language interpreter runs to this interpreter and if it passes the validation and interpreter, gives a new state, the same process repeats, involved parties just to validate that you are proposing something that, after which the changes are being replicated and the system, and the state has been consistently updated. And the reason why you need to attach some currency to that is just to make sure that you don't waste other people's resources. So that's why you are paying upfront, and some of them are going to get these funds as a reward one way or another.
So the question is what can possibly go wrong with this. As you're probably aware, many things, but part of smart contracts themselves, but happened to be introduced. In there, and I'm going to give you a three particular scenarios of how things can go very, very badly, using my favorite characters from Futurama. I mean, Lila, and Professor François. In the first scenario, me decides to score some funds, and she does it in a very fashionable way. By making decentralized content company.
So, in this campaign, the most important function is the one that will allow me to withdraw the donations as a part of the validation in the function withdrawal so she can take note of them and probably think them properly. So me knows that the type sound as guarantees provided by the ... if there are no exceptions, it will draw no exceptions.
Amy is wrong is the judgment, contrary to expectations, B is informed. MLnd this is certainly not the center expects and in tourism and that if a type has done its exception for you. She is wrong. Let's see what can possibly go wrong, out of them.
So once me has written her contract and deployed on the blockchain. She has no way to take advantage because the contract and the state has been have been massively replicate it. After that lucky start to get some donations. At the point decide to exercise her her mighty campaign and withdraw the donation backs The best thing happens, if at least one of the data submitted their own data. So the exception is strong, and the contract blocks this money forever so neither the backers can get it back. If the contract is structured in a certain weight neither me can enjoy for cash. So this is certainly not a great scenario.
Let's see what else can go wrong with of language frastructure so now we are focusing on Lila, who is a language engineer and Lila is in charge of maintaining the reference interpreter for the language that gives the logic to smart contract deployed on the blockchain. Following the suggestions by the users.
Sorry, little decides to add the operation for computing the power of a certain features certain days, or certain arguments and GHR implementation is perfectly correct. The only problem is that it takes linear time in the size of the argument, to compute the power of number.
Remember this is computationment in that computation that is going to be validated by multiple parties, not just the one who deploys the respondent transaction. The problem was Lila's code is that it disproportionately charges too little of cash for computing the power function where the cost is linear, the implementation only charge logarithmic costs. Let's see what can go wrong now so now when this is interpreted this interpreter is a part of the time for the blockchai consensus, but we have a discrepancy, the fact that transactions that have to do with computing the power of a number of very cheap to propose in terms of the funds that needs to be allocated for them, but they are quite expensive to execute in terms of the real computing resources and it doesn't take long for someone to recognize that fact, after they will close it was messages to cause contraction contraction, and eventually denial of service and then I will serve as this is a real pain in blockchains as somebody with, with my older posts and particularly unpleasant, when they're called cost by the language implementation, not some serious networking issues.
Okay, so that was probably the most exotic one let's focus on Professor funds fourth, who decided to solve the performance issues in radical could processing. Everyone likes, professor...o, this becomes the de facto part of the client and everyone starts losing this compiler for every single smart contract in. The only problem that this compiler is too cleve implementing certain optimizations, it hit famous complexity results social circle control flow analysis, taking a cubic time in the size of the program. And again, it doesn't take long for someone to recognize the efficiency and leader of the system with the contracts that are very small, but those kinds of optimizations look into the congestion and to the denial of ervice in the system. Okay, now we have seen three scenarios of rubber plants are unpleasant consequences of what I'm going to go language letterbox. Anthose are not the backs of the smart contracts.
Those are the bugs in the infrastructure that executes the smart contracts invalidate the smart contract, such as the type checker and an interpreter, such as the misalignment between the cost semantics and execution, and real education costs, and finally the box in the compiler.
Okay, so in this talk, and then the rest of it, I'm going to tell what what we did in language layer of the real world blockchain, using tech also firstive oallvery small, smart contract language which is built, or based on system with some extensions, it's intentionally non Turing complete it doesn't but it has recently different effects and all the interactive smart contract is structured as communication between independent actors. So this is a practically relevant language it has been adopted by a block chain and there are several 1000 contracts within it and when users are using the code returns filler daily If you're interested more in the details of the language itself out, ee the usual suspects, such as the type of structure and the type application. Also has no camo style imperative fragment with reading, writing, mutable state emitting events, and sending the messages, and the context of look like that you don't really have to read this, you can just notice that well, there is such a contract definition. There mutable fields and the whole structure as conditions that most time results in sending and receiving messages. So one interesting detail about implementation of silver, which is by the way, Don is interpreter, which written according to best practices in the monadic. So, monad. So not only the use of molecules quite justified so you can see the Oh camel led by innovation and highlight the the structure of the interpreter will be essential for engineering for the best thing we are going to adopt the standard mechanism of property based testing, write your properties as Boolean functions to implement the generators they played random inputs and write your properties as Boolean functions to implement the generators they played random inputs and nd has been replicated for multiple languages, and settings. Okay, so the property based testing becomes really interesting when we want to test metal properties of the language, such as the preservation so e key part here is a most of these properties.
They're really conditioned on certain vendors. And as you might know, even if they wanted something as simple as the type there's a reason, we really need to generate the term which is well typed in a certain context and solution to that which has a very little chance to work, is to generate the environment. The term and the type and check if we are lucky to have this to be well typed with regard to this type. And if not repeat this process so this interesting part of chicken the meta property itself, and much more clever solutions used to write the generator that first purchase well form types, and then based on them, reduces the chance, and this is something that has been studied quite a bit on the last few years years.
It's very much recognize to be a non trivial problem some solutions to that. I found instances in the framework section, nd more recent work by some of my coders who tested non interference Using generate on well for him to programs. Okay, so we follow this approach and we decided to adopt one of the state of the art schools for property based that provides good possibilities to generate types and structure data.
And quarter of this work. Had quite a bit of success in academia and used as teaching material in the software foundation Sed as teaching material in the software foundation series. So one of the reasons that we decided to switch it is the fact that it's very well formed programs it's also has a reasonably good interaction with which is a language in which still has been implemented and also has some advanced features such as fast and based feedback, which simply we didn't have to.
We some interesting gotchas that we have figured out or adopted from the published report, when engineering our tests and approach to seller language layout. So the first challenge that we have faced is how to generate interest in programs in the fragment of system and what makes system layout. So the first challenge that we have faced is how to generate interest in programs in the fragment of system and what makes system quantify polymorphic types, or this is not particularly difficult, we can do it in a recursive manner by first Remember in which, which type variable, we have in term, variable as free. Ands fundamental So that's relatively easy, somewhat more interested in is how to generate type application so this rule doesn't quite do justice to the problem.
So, I'm going to write at that rule. North so the main discovery we made to generate the type sigmas. And generate, tau, and tau prime replaces variable ex-, in the Ta, u and the x in retro specific . And so identify close symtack TAM ite idea is to take the type sigma philosophy and identify closed subtypes type variable so that as simple as it sounds, was just a driver or so and recording of types. Well, in reality, the algorithm was slightly more tricky, because we need to keep track of, of the type and also distribute frequencies so we wouldn't get very boring subtypes.
All the time. Okay, so that was one discovers the second one has to do with how we harness the language infrastructure already in place to facilitate the assessment, and for that. So the main motivation for that was to test a particular component of Silla compiler, which implements a control and type flow.
Remember in functional languages, the control flow analysis typically over approximates the flow of values to variables, was the main application of that being optimization function inlining and somewhat more vertical analysis approximates the set of ground types that flow to type variables, who is he main application of that being more physician, unsurprisingly to test these both we need some version state collection semantics.
Hat indeed flows to the type or value variables and primetime is correctly approximated by. The only problem that we didn't have the semantics of it. The only thing we have is our reference interpreter, and has been written in monadic , and how to abstracts the interpreter, and some of this affects, MOITH have corrected. And long story short. We only had the change the instances it. So it would report all the states. And this way, we have implemented someplace to he were P with you inn... so here to hear about the full box.
And this is was the box as of camera ready submission, which slightly increased since then.
There are some not worthy specimen here.
That happen to do with misalignment between the static and dynamic semantics of the primitivesprimitives. And have two box, that deal to denier of service.
One problem of interpreter itself. And mentions in the example, and finally, bug in the compiler, the counter flee left laneh made counterflow take pretty much forever so we had to do some contrast conservative projections that are going to be compiled you can also see that some of these bucks are really known so what we have done we have taken the previous commits, where this came from last reproduce before they got fixed, and we automatically generated programs just to make sure that our framework posts will be able to produce this box, but 7 out of 10 entirely new.
So, just as the last example.
So here's one of the box which in retrospect is extremely silly, and I wonder how the developers missed in the first place.
In the first place, but this is what is happening here. So here we have a type abstraction with two names of the same type variable used twice. And what happens is that the interpreter should really think that the type. The type of the variable we want is V prime.
In fact, it decides at runtime due to shadow and the type of we want is this We prime, which is closer in terms of scope. And variable A, 161648. Truth been detected. And I believe it this is the time I have left, to take away from the experience report, something might find useful, experience of... several credit... ish PSHL blockchain based on system using which as a tool and discovering several critical bugs. There is a simple technique of and sub-Constitution for generation the wealth out FF system.
Type instantiation. The real world usage of the technique of monadic interpreters for implementing collection semantics, that's static analysis. And if you want to see all that in action, we have an artifact Publishing's and others so feel free to download it and take a look. And this is all I have for today. Thank you so much. [APPLAUSE]
>> Quick questions before the break?
>> John.
>> That was very cool to see, can you just go back to the last bug you showed us?
This one
>> Yes. And what case like this, let A equal, it's equal.
I wonder if this is bug in simple lest form, if not, say how much you... the question is how do you imply... the fact he we see chain of... isn't in his is, this is a part of the language. So the example has already been shrunk.
>> So is the simplest possible form then.
>> I think so.
>> Another question?
>> Could you explain why you switched to property based testing, compared to formization that proveds one thing and forgel.
Ish infrastructure but it made possible for one of the earlier versions of Silla that evolved since then, to verify properties ... of smart contracts itself.
So we will never we never dare to go full blown concerts with Silla inside and we property based testing of the language infrastructure to be a viable, and the pay as you go along to the hardcore verification. In.
>> If you have any further questions, maybe it's a good idea to ask them during the break and thanks Ilya again.
[APPLAUSE]
>> And it's time for break.
