Welcome to ICFP 2022.
Welcome to the second day of ICFP. We started the second day with an invited session, and my great pleasure to introduce you to the speaker Delia Kesner, professor of Computer Science at the university in France. And current research interest span many area of logic in Computer Science, rewriting theory, proof of theory, and articulate the applications and areas of functional programming, and theory of programming language in general. Her contributions very diverse, working on explicit subs introduction, lamda calculus, and is finish nets. Pattern calculi but they appreciate a lot about Delia work, also for simplicity and beauty. And I think this is one of the reasons why she as been the mentor and teacher of so many students, and so many researchers so far, And I think today she will tell us about somesomeof her recent work about quantitative tightening. Thanks Delia
>> DELIA KESNER: Thank you.
[APPLAUSE]
>> DELIA KESNER: Thanks for your kind introduction, it's a great pleasure to be here with all of you to share some of my past and current work.
And okay, so what this talk is about?
I would like to: About quantitative properties of different models of computation in a unifying framework. What I mean about quantitative properties. So take into consideration time: How many valuation steps a program needs to require. And very notion of space how big result of a programme is. Which of the different model of computation.
Let's try for the moment to talk only about call by name and call by value but it's already an ambitious goal, I think because they are here to unify the view on call by name and call by value in a unifying framework which is called the hich can be seen as a call where put value like leverage is assessed subset, in some sense offCall-by-Value. So let's take this picture of the insights of the work. Can be seen as black box, not a square box, black box, in sense you have different tools can pick some tools in order to define different models Call-by-Name, Call-by-Value.
And fantasy some other model of computation that can be specified with this black box, and concrete goal is capture time and space measures for these coloured systems by reasoning in the black one. So have motivations and applications in semantics of programming languages and in particular in quantitative semanticss, can be used in cost models, to resource computations, and to have inSIEKTs in efficient implementation of programming languages.
So let's start by recalling what is call by push value, and main ideas, we will find in bank calculus. And introduced by PB Levy, a long time ago. And extends the standard lamda calculus, and split your world in value and computation, and mix them in order to go from one to another, and value to computation, and to value. In this way, can capture in a very interesting way, and we will see some technical details later how to capture and encode Call-by-Name and Call-by-Value strategies.
So this is related to linear logic, and this was stressed by Ehrhard years ago. Call push value you have attention between values and computation, and linear logic, a tension between linear and nonlinear resources. But during all my work, I'm trying to use in distance coming from both in order to develop my ideas, when, when I talking about nonlinear resources I mean there was had that can be erased and duplicated okay well the linear ones cannot be erased and duplicated. What is testing is testing is Call-by-Value and NAIM. So can give insight how to use unifying framework to talk about these model computation. This is more or less plan of my talk, introducing concrete way of calculus. And discuss, some untied properties and how you can capture provide name equal, equal value none and typesetting, then we will discuss how to typing, which is a very particular typingyou will see and then discuss more current work related to invitation, related to quantitative reasoning, so let's start with the bang calculus, and some history behind that.
First bang calculus was introduced by Ehrhard as I said before in order to bridge the gap between Call-by-Value and linear logic, but first calculus is incomplete, here incomplete means you can write terms, notationly nonterminating, but they are blocked, in some sense normal form, and paradox, block term can not be nonterminated.
This was repaired by Guerrieri the same year. So you recover completeness, and very easilycon fluence. And a way to repair that is to reason with calculi with distance and I will explainexplainwhat is a technical tool to do that and this was done by with my colleagues.
So a little bit of syntax.
Don't be afraid. You take lamda calculus, and extend lamda calculus, and one operator to denote value, and call push value. And one operator transform value by computationses. And substitutions. And there is no reason to call them explicitly subs Tuesday, but in a very concise way to save space. And operational semantics, very simple, given by 3 roles. The key point you never reduce inside bangs. So you never reduce size values, and exactly Call-by-Value. You never go inside values.
So the roles are very simple, these are not definitive ones, but gives me opportunity to introduce them in a very simple way. You have one rule that fires reduction. But you are not performing beta reduction, but introducing a binding, which is exlicitly here, and bstitution, you need the content of the substitution to be event is exlicitly here, and So this is why it is called called a plus value, and you need so to mark in an explicit way the fact that you have a value,value,, and you have a third rule, they are to remove all the KURNs of... followed by by the bang, if you take only these rules, you don't have good properties and you need to ad d what is called disconstant operational semantics, distant operational semantics means that in the middle of things cooperating, interacting, you are going to insert a list of let bindings, this is called a linear context, and the result is that now you have these rules, and in the middle of the interacting terms, you can just consider that you have a set of let bindings and sequence of let bindings and this is inspired from linear logic.
So here, very small example, if you take identity, K come bynater, delta and omega, very well known lamda terms, but here taking by the call by push value, and by using Bang. And starting from this term, you can apply, and eliminate the bang, and k operator, and can perform, steps to start to fire reduction. And you can see in the middle is a distant context, and you can continue anyway, this is not BLOSHGS you and have two substitutions and can continue and get a normal form, this notion was originally introduced with my colleague Pena Nietol, and lamda calculus, and here it is applied in a more general setting but the idea is the same and you recover very good properties by using this kind of by defending this kind of system where commutative conversionsconversionsare inside the computational ones, so don't need communetive converses in independent rules. While some nice properties, this system has a linear logic flavour, as I said before.
Because erasable and duplicatable terms, need to be explicit way with a bang. So the substitution role you want to fire substitution, you need a BANG, so a very resource aware semantics. Calculus is complete as said before, if you have a block term, and nominal term, and nonterminating program, and another one, technical problem property, it's very nice. It's not a deterministic strategy, the calculus is confluent, and more than that... if you can look at... we'll see the picture.
All the path, all the kind of sequences you can construct to reach a normal form have the same length, why is that. This is very strong. But why is that. You never reduce inside values, so this typically from calculi, where you never go inside the objects that are going to be erased or duplicated.
So, let's talk about how we can capture Call-by-Name and Call-by-Value. And just to recall, here I don't think I need to recall. Call-by-Name is the strategy where arguments are consumed without any provider evaluation. So that means that any kind of argument can be erased and duplicated. In Call-by-Value, you need a value to make iteration or duplication. So let's keep this in mind in order to through the translations.
So let's start with the translation between Call-by-Name and the bang calculus.
So the idea, the general idea is that we want translation capturing static properties, that means we want to compare a term versus the translation of the term in the Call-by-Name translation.
And also, we want to reason about dynamic properties, that means to compare reduction sequence in original lamda calculus, in respect to reduction sequence of the translated term in the bang calculus. And you can do the same for Call-by-Value of course. And what you expect is to have properties like that.
So Call-by-Name for example, you want to show, every time that a term is well behaved with respect to some property if and only if the translation of this term in Call-by-Name is well behaved in the bang calculus.
So let's keep in mind this expected properties, because we're going to use these along all the talk.
So this is a technical slide.
But... maybe I want to stress just the important property of this translation maybe without entering into the details.
When you translate Call-by-Name to the bang calculus, what you want is to mark with a bang, to say in explicit way which terms are erasable and duplicatable.
NAIM you can erase and duplicate any kind of argument, so you just put a BANG behind the arguments, right hand side of applications and contents led by -- and that's the translation, Call-by-Value translation, Call-by-Value can only duplicate and erase values.
So here framework of open Call-by-Value. And you can see the values, variables and abstractions. So you but the BANG in these cases. Okay. And relicto, in, on the left hand side, Call-by-Value case.
Because in Call-by-Value abstraction is translated to value. But value can not act as computation. So you need to remove this bang in order to use it as computation. This is a technical issue. What is interesting by using the translation which is known in linear logic as the --
translation, you very good dynamic properties, Call-by-Value by name and Call-by-Value translated by the bang, but you don't have good static properties in the sense that if you concentrate on terms you have normal forms in lambda calculus, not necessarily normal forms in bang calculus.
So you can change this famous translation, by using rewriting and super developments and will not discuss the details, but what is important that you look over the static property. And by using more sophisticated translation, and now have translation which respects normal forms, okay?
So these are defined with my colleagues. And these are the ones that I'm used to use in order to reason about these kind of languages.
So remind expected property, we want every time to have good property for, the property of translation of. And some example of this was proposed by Faggian and Guerrieri, and study a property and we're writing called factorization. I will not explain what is factorization.
But very first example of what you can do by reasoning unifying framework, and show what you can do factorize, by Call-by-Name and only factor in bang calculus, and translation, showed before.
>> Another property, qualitative properties, in the sense these properties not talking about time and space for a moment, so let's wait a little bit, in order to talk about quantitative properties, but nice qualitative property is the one related normalization, of one term with respect to normalization, of the translation of this term.
And so this theorem is very important... this is the kind of qualitative property we can expect from a translation, which is really preserving the good semantics of languages.
However here, we don't have information about quantitatety, and so the question is how e aluation time and the result in space is preserved by this translation. . In order to do that we need more expressive framework, type framework, and sense of denotational semantics, it's not necessarily a type system in the sense of programming languages, and you will see why.And, of course, when you talk about that, you only start from simple types in simple types have you if you restrict your attention to and normalizing you see if you type termer is terminating, you will always have terminating terms, that are not typeable. Ypical example is the self application, X applied to x is terminating but you cannot type it,in a simple typeable. If you want to capture also terminating terms, one is intersection types, and so here intersection is an operator, such that if T is of type A intersection B, then T is type A, and of type B at the same time. And that's why you can type now the self application, because X applied to X has algorithm effects that is function, and another which is argument, and both can live together which is no problem and recover completeness. Of course this type system can not be decidable, because this type system is using to characterize termination. Okay. In the intersection type word there are two different ways to see intersection, and one is to consider... this was initiated in particular by the school in the 80's, in order to study denotational semantics of lamda SLUS. And nonidempotent ones, which have linear logic flavor, and in particular, the first one that I know is the one with Girard, this intersection is associative commutative commutative and either either important or not, and you know when you have these actions, you get set. Or multi sets, and this is exactly an intuitive way to explain whyon the idempotent say, you can only show, qualitative properties using intersection types. So qualitative in the sense, you can just say if and only if it has the property but nothing else. Why didn't know, non idempotent towards you are using multi setdata structure which is useful to count, so you obtain quantitative properties and this was Carvalho. Who started this line of work. Some years ago now. So let's see a little bit of syntax again in order to be more concrete about the systems, let's consider the types can have multiset particularly on the left-hand side of the arrow.
And so these are multisets where a type can occur more than ones, and in particular not only the same type more than ones, but can have different types.
For example, functional type.
This is multiset, ask this system called system B and this is original for system for lamda calculus. And so you have standard rules for application and abstraction, but what is important for the system is relevant, relevant means in the action are you not using weakening in particular.
And so you need in the application rule, and in the explicit rule, binary rules you need to collect all the information that comes from the different branches of your type of derviation and this is ultiplicative play more this terminology from from linear logic. And what is interesting in the bang rule, you will see using the hypothesis typing for a computation. And from that you construct value for the BANG. And typing for the value is multiset, which is the one being able to count things, and for the... deletion it's the opposite, if you have term with multiset just one element, and then from this value you can type the computation term.
The details are not very important, just to be more concrete, sometimes it's necessary to in order to give concrete ideas of what we're telling.
But it's not important to understand the rest of the talk.
And so an example of qualitative property.
So if you take the previous system without -- by collapsing the multiseting to set. And then you can only show this kind of property, a term is typeable if and only if it's normalized, remember we only have... also have completeness. This is the kind of of property, where you say yes or no, and nothing else.
And from a quantitative point of view, this time you take multisets, as in the previous slide, you can show typing in place normalization, and also, you can guess and extract from the original type of deviation the measure. The measure is given by looking at the size of the original type of derivation if a term is typeable, and type is called pi, then the terminates bank calculus, and giving result of space S, and this L and S are bounded by the size of the derviation, and this was explained well yesterday. Device you extract the measures of time and space.
And that means in your type of derivation, are you anticipating the measure. And this is concrete example, you can do with different models of computations, and even with classic logic. In particular you can have some complete results from quantitative point of view for the bang includes, and Call-by-Name and also by Call-by-Value. But the question here is if we can get soundness and completeness for Call-by-Name and Call-by-Value by only using the result of soundness and completeness of the bang calculus. So if you remember my picture, I want result from red and green part by only looking at the black box, okay.
So how can we do that?
Well... the idea, remember, the expected property, in order to do that, we need in some sense to connect T and the... T in Call-by-Name, for example, and the translation, the Call-by-Name translation of T and bang calculus, so what's possible to connect here?
We're going to connect the type off... so it's easy and simple to show. I didn't show the typing system for Call-by-Name and Call-by-Value. But they're not necessary here to understand the main purpose, and here the idea is that by looking -- just by looking at the typing system, you can show that a term is typeable in Call-by-Name if and only if it's translation is typeable in the bang calculus.
So since this typing systems are complete in the sense that typability if and only if normalizationnormalization. Then you get this from a quantitative point, and quantitative corollary, and quantitative point of view, you can see... vague but already interesting, upper bounds of BANG includes relate back and forth to upper bounds of Call-by-Name and Call-by-Value.
Of course this is not very, very, exact. So the question is, would like to do better.
And why would like to do better?
Because if you concentrate on upper bounds, upper bound means here time + space is bounded by something which is giving by the typing operation, then we have this problem caused by the size explosion problem. And the size explosion problem says you can have an exponential GAM between time and space, and that means not very interesting to measure them together. It would be better to split space and time.
In order to do that, you generallyize this kind of systems to what I call exact systems, and the name for this system is... for one of the bang, and Call-by-Name etcetera.
And in this systems you can split... so have a picture in order take intuition of that.
You split the measures and type of deviation. So the type of deviation, is able to say, the type of deviation is computing corresponds to time and space, and in order to do that, you need to use another kind of typing consequence in which you use counters.
It can also be done without using counters but by looking at -- very simple way to understand these systems, is fixing counters, one for time and one more space.
And this was introduced with my colleagues. For lamda calculus, and can be extended for different models of computation, and now applying to the bang calculus. Yeah, so I don't know...... so, just to continue with this idea: This is a typical typing rule that you will use to specify exact systems.
You will have typing deviation for subterms, and information about time and space, and from that you will construct conclusion typing a term where time and space counters are just a compute using using some functions, and very, very simple function which depends on the formation coming from the hypothesis.
This is just to give an idea, but not going to show an example of these systems.
Well... again, which is the kind of properties that you can obtain by using exact quantitative types. Again, we call that, you want to show T has some property if and only if the translation of T enjoys, also this property, but in another world.
So you can do that by using discounters, so you can show had a term is countable, time and size t and s if and only if the translated term committed typed in the bank calculus, with the same counters, so that means translation does not cost anything. Call-by-Value case you can show time and space change a little bit when you go Call-by-Value bang calculus in particular concerning time.
Pive and not going into the details of that, but it can be said in a very precise way which is the time you need more in order to translate a term by using the translation I used before by Call-by-Value to the BANG calculus.
So collary, exact measures for time and SDIES of BANG normalization, relates back and forth to time and size of Call-by-Name and Call-by-Value normalization. So let's talk about inhabitation, current research topic.
So this in principle is a different type of property about quantitative property. But it's very amazing to see how nonidempotent types gives here, interest reason about invitational proof.
So when you have typing system, the typical kind of question is:
I have a term, and I would like to find a typing environment gamm an and sigma type in order to type this term in given typing system.
If you take simple types for example, this is the decidable.
But very easily, when you go to intersection types you become ununsidableundecidableundecidable. Why is that, because normalization...
againing typing systems are used reason about semantics of programming language, so now let's look at dual problem.
Dual problem inhabitation, you have context and type and want to find a term which is typeable with this context and this type.
In simple type this is the decidable. With important type this is undecidable, and show...
along time ago, and surprisingly or not, this becomes decidable in Call-by-Name for example, and this is result I obtain with colleagues.
And so... I will try to explain why it becomes decidable. But also, the idea is that, understand this works for Call-by-Name, and also like to know if it's possible to obtain this kind of results Call-by-Value and other models of computation and particularly framework, that could be encoded in the BANG calculus.
Which is intuition when you use idepmpotent types, 1 + 1, = 1.
In non-idempotent world, 1 + 1 = 2. So you have a perfect tool to count, and to bound your interpretation algorithm.
So when you INTEFRN in idempotent types, you have infinite set of resources and don't know if you can stop or not. And... other, you have finite set of resources, And so we, when you don't have any more, any kind of resources, you stop and you know if you have your solution or not. Okay, this is an intuition o how we can how we can proceed. Well it first goal could be Well, I would like to know if decidable Call-by-Name or Call-by-Value.
This can be the first call.
More ambitious goal, now that I have the tools to connect Call-by-Name and Call-by-Value with bang calculus, I prefer to reason in the BANG calculus, and prefer to have... to transfer this result to Call-by-Name, and Call-by-Value.
And so this is related to this picture that you saw before.
And more ambitious third goal.
Decidability, having interesting third model of computation encoded in BANG calculus, so would like to have general methodology in order to reason in the BANG calculus and to export to encodable computation in the BANG calculus.
So this is the... we follow the third goal.
And by of course, we started --
I mean, giving solution to the second one, and then realize how to deal with more general frameworks.
So this is joint work with colleagues Arrial if Geurrieri, so the computational problem, you fix the typing context, and fix your type, and you want a term.
So your term belongs to a language, in this case, BANG calculus, and your types belong to TOOIP system in this case, system B I showed you before.
So now how we're going to proceed?
Yeah, instead of looking just for one solution -- I mean just for one term, which is inhabitant we want to compute all the solutions.
But all the solutions, I mean, it's difficult, because you have infinite solutions in inhabitation problem. So what we're going to do is transform infinite solution in finite set of generators, and this is done by reasoning about normal force, and we can do that because our typing system is characterizing normalization, so we can restrict the attention to normal forms.
Well, in order to do that, you need to... you need to understand which are the good rules to look for inhabitants and this is related to different things, one of the rules typing system, this is evidence. And another thing, the evidence you are going to propose belong to grammar. The grammar generating the language you are working.
In this case the BANG calculus.
In this case our grammar is grammar for normal forms, and why it's efficient to look for inhabitants in normal forms, again, because the typing system is characterizing normalization.
And another difficulty is to be sure all the recursive calls are good recursive calls in the sense, you will be able to show determination. So I won't detail the algorithm, but the algorithm has this kind of scheme, and have different roles, and left hand side, recursive on the right, and algorithm is written in nondeterministic way, you do for example, in modern specification. And idea is in a particular situation you can apply many different rules, but in the end, you will terminate.
This is the idea. So of course I will not enter into the details here. But this is very non-deterministic specific occasion of the algorithm. The good quality of this kind of algorithmalgorithm it's elegant and easy to reason about determination, and usually difficult property to show on these kind of things, and soundness and completeness.
What the meaning of soundness here. Soundness if you generate some solution by, I said, remember, you compute set of solutions and not only one solution, and then, for any term in this set, you can type it with input you gave to the algoritma and completeness which is more difficult to prove as usual, which says if you have...
any kind -- normal form or not, then can you find a solution with our algorithma and this solution generates T, and has very concrete definition related to reduction.
Okay, algorithm has been implemented by V Arrial, and fun to play with the algorithm. And this principle can be understand working on the BANG calculus, and so what about Call-by-Name and Call-by-Value. Remember, I didn't mention -- because, again, it's a technical point --
but, if you can see in this rule there is a parameter here, a parameter related to a grammar.
And the kind of grammar that you use in the algorithmalgorithm, is the grammar you need for BANG calculus, or Call-by-Name or Call-by-Value. So you want to reason in the BANG includes, you use the grammar for normal forms of BANG includes. If you want to return Call-by-Name and change the grammar and so on.
This is the kind of parameters that gives you only one algorithm to solve all the problems at the same time.
So how does it work concretely?
Let's take the case of Call-by-Name, you want to solve the navigation problem for Call-by-Name. So you have some input parameters, Gamma and sigma. And have grammar for normal lamda terms, but algorithm works in BANG includes, you need to translate terms Call-by-Name to BANG calculus, using the translation I showed you before. And then you are in image of Call-by-Name but in the BANG calculus you solve the algorithm, and then you come back with antiencoding, this is an easy way you can use one tool to solve different problems. And same thing for Call-by-Value. You have a problem, but now in a different language, and go to the BANG calculus using another translation, so you need translations for that. And you restriction attention to the image, and work with the image, using the algorithm for the BANG calculus, and then you come back.
Okay, so now coming back to this table... we have this decidability of Call-by-Value, and not just decidability -- I mean we have more information than decidability, because we constructed the whole set of inhabitants of particular instance. So these more familiar with proof search this is very similar to what is done in proof search for logical systems and can be use particularly case of program synthesis, particular case, because you are working in very particularly framework, and using specifications that are nonidempotentize, and can be seen as program synthesis, I think I can present some of my conclusions. So first a little sum mary about what I presented.
One idea, is show the unified and tape framework, and capture properties Call-by-Name and Call-by-Value in typesetting.
And then the fact that you can enrich the framework with types.
Of course you can use other kind of typing system; and also of course decidable type systems.
Here I use this to reason about quantitative models, and what you can obtain is systems that are able to specify upper bounds for time plus space, and also you can refine this idea in order to obtain exact measures for time and space separately, independently.
And we have also seen inhabitation algorithm that captures, the solution for Call-by-Name and Call-by-Value.
And so now some farther questions, and on going works, and methodology developed here can be used to reason about other qualitative but in particular quantitative properties, and in particular approximation, solvability, space computation measures, as presented yesterday, etcetera.
So these are more questions than ongoing works.
And another question is how you can extend this in order to consider more expressive features, like, for example, pattern matching, and global state, and control operators, etc, and how to extend this to go to BANG calculus very particular case of Call-by-Value, and also to those that are more expressive. And this is question that someone is going to ask, what about call-by-need. At the moment this kind of framework is not able to capture call-by-need.
So another goal would be to define a clean logical explanation, a clean framework that is able to capture, at the same time not only Call-by-Name and Call-by-Value but also call by need. And thanks for your attention, and I'm leaving my contact information.
>> Thank you.
[APPLAUSE]
>> We have time for questions.
Yes, please.
[Off mic]
>> Yeah, I was just wondering, do you see this work applying to practical programming languages?
>> ?
>> Practical programming languages.
>> DELIA KESNER: There are a lot of connections for example with graded model types, but this is more general in some sense. Why is that?
Because in graded model types you can specify -- for example in the case of positive integers, you can say I'm going to use this resource N times, okay... and that's okay. And that leaves you possibility to have size type systems, this is generally... because use of type A is nonimportant type, and this is more general, in some sense, you are giving a foundation of this kind of system, and foundation that comes from logic, So I think that it's very good to connect practical features of programming languages to foundations in logic and lamda calculus.
So this could be one of the things.
And another application is if you consider that the reasoning that you need in order to understand efficient implementation also from logical point of view, this gives a lot of insight about these kind of things.
And also, about cost models, as it was discussed yesterday in the first session.
So, if the question is, can you take exactly this typing system, and implement a compiler, for a functional programming language, of course the answer is no, but here, the application is kind of application with semantics, so connect concrete languages and concrete features and properties of programming language, I think the efficiency for example is one property which is interesting for the developing programming languages to very formal tools that have good logical foundations.
>> Thank you. Can I ask one more quick question. Have you considered the unique inhabitation problem. The question whether there is only one inhabitant.
>> DELIA KESNER: No, no.
So... in this framework, you don't have a unique inhabitant you have a lot of inhabitants, and so... maybe a future question is what we learn here working in inhabitation maybe it would be interesting to connect with other problems, one you are mentioning, and others that are interesting. But this is future work, and needs interaction with people working in this kind of inhabitation problems. Yes.
PSH
>> So I might have misunderstood something you said, but when you say you can give quantitative bounds on time and space, are these bounds that can be expected to be only a constant factor of the way of actual time and space cost, or should imagine to be polynomial difference in practice.
>> DELIA KESNER: Are you talking about upper bounds right.
>> Yes, so if the program gets time bound from the typing judgment, can I expect that to be reasonable estimate.
>> DELIA KESNER: The upper bound, as said before is first approximation work, another interesting, you obtain bound time plus space, and have exponential gap between the two, it's theoretical result but not so exciting. If you choose exact type system, I mentioned this type of work a little bit quick. But they are the more interesting, and also more technical ones.
In this kind of systems, you guess, because you are guessing, you have unsidable typing systems and are guessing. And you have exact measures. So you obtain exact measure for the time, and exact measure for the space.
So that's much better than the upper bound.
>> Cool, thanks.
>> Can I stick on the same kind of topic.
So, as I understand it, big feature for you, bound on the time and space of the program when you run it is bound by something of the size of the typing derivation for me as compiler writer, that means the programs will take as long to type check as they do to run.
And my users would not be happy.
And yet, very strongly RESnate, we want to connect real programming language with foundational logic stuff. Can you help me hairy chested compiler writer with the quantitative stuff.
>> DELIA KESNER: The same answer...
>> Maybe I didn't understand the answer. Try again.
>> DELIA KESNER: Okay, I will try again. Of course it's very bad, this is first step, this is work initiated by Carvalho. And the first step towards understanding this nonidempotency is interesting to measure in very generic way. When you want to measure in more precise way you go to the right. In the right you extract the exact measure for time, and exact measure for space, space in the size of result, that means in typing derivation you have a number, I don't have an example today, but can point to papers where we have several examples, and typing derivation and count the nodes, and you can split this measure, I mean, more than that.
From the typing derviation and have two counters, and you type your term, you have two numbers, one is the time... the evaluation time, and the other one is the size. So you have exact measures. And these ones are the real ones.
>> So maybe you are saying you can have a small derivation with big numbers in it.
>> DELIA KESNER: Small derivation depend on the term, these are real measures, in the sense you have 3 steps, it will give you the three that correspond to the size of derivation, so if it needs 1 million, it's very big.
This is semantical tool, it's not a typing system that is supposed to be implemented in regular programming language.
But the type of deriva to my recollection on gives the exact time evaluation.
>> Thank you. From what I understand your term language doesn't include a fixed point or recursion operator. So really capturing strongly normalizing terms, then it makes sense quantitative system with this intersection types would capture the number of uses of the variables, and so would bound the space.
Do you have any idea how to extend this, maybe maintaining termination for something like folds or some higher order functions and data structures.
>> DELIA KESNER: This is very interesting question, and of course, I have already tried and it's not easy at all.
So there are some ideas of the use of impertant types in recursive programming. But I don't have a solution. It's of course a very interesting solution -- question, sorry.
The idea would be to extend the language in order to at least to have recursive functions, and how to deal with that, and if you have very simple structures, list and trees, etc. First step done with language of pattern matching. Because pattern matching is already complex, if you want to compute measures of evaluations, because you need also to measure the time that you need to pattern match.
Okay?
But in the world I have on the topic, I don't have recursion interesting that data structures yet.
>> Other questions?
. Here.
>> Thank you for the talk. It was very accessible, I was able to follow along.
So I thought the result was very nice, very interesting that you were able to get decidability for the inhabitants problem of this type system.
And I was wondering sort of, working in synthesis, obviously we work in different type systems that are decidable. But are there any insights from the work that you could potentially extend to practical programming language or programming languages designed for synthesis. That could make it easier to solve the inhabitants problem, so when you're doing program synthesis you're looking for inhabitants of sort of some specification. So I'm wondering if there are any insights from the theoretical side, that could be used to inform, or move the type systems that we use for program synthesis.
>> DELIA KESNER: So I'm not an expert in program synthesis.
What is interesting here, when you... look for inhabitant and your original type has graded information, and so you find interesting solutions, for example... in lamda calculus you can encode numerals, so you encode as input type No. 2.
Then you obtain program that corresponds to CH No. 2.
And when you use impotent types you don't have these kind of solutions.
So it's not an answer to your question.
But it's the kind of things that are interesting in quantitative types that you don't have in standard types.
>> Okay, so let's thank the speaker again.
[APPLAUSE]
