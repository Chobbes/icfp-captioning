yeah, Anton Lorenzen, finished my masters, and starting Ph.D. in Edinburgh in the fall. And reference counting with frame limited resouse.
And before I get into the work want to say a few brief words about where the setting takes place, So while our work is general enough to work also outside of the setting I think it really shines here. So we start off with the Koka language, which is a strict functional programming language with strong typing. And in particular, it has algebraic effects, and the first step will compile this algebraic effects away into pure lambda calculus, using the evidence passing style. Introduced last year in ICFP. And then we go from the pure Lambda calculus, to C-code, by inserting reference counting instructions, according to the, to the purchase algorithm which was also introduced last year at PLDI. And a nice thing about these two steps, is that none of them need to capture the stack in any way. So in particularly obtain C code, just use standard malloc and free. There's no need for any kind of GC, or root scanning or any anything like this. Before I get to our contribution let me talk about Perceus, . Unlike most reference counting implementation it's not...
based. Northe have a list xs here, and we met over this list, creating a new list ys, which we then print, and most reference counting and struck implementations, for example the one listed below. Drop these two lists at the end of the scope, in particular means that those lists are live at the same time, both in memory printing YS this is unnecessary, because XS is not needed while printing YS. And that's what Perceus does, passes ownership from the map function to the print function, and now XS is dedeleted while YS being constructed. So how does this work in the map function? So I'll focus on the first construction. We got on the cell Xs, we matched on it. And we want to continue using x and xs. So the first step have to increment the reference count offer the children, inserting the stop inSTRUSHGS, and have drop instruction, which gets rid of the cell excess, either by decrement the reference count all by freeing it if the reference count happens to be zero after the decrement. And particularly nice fact about this, now xs is delated as soon as possible, match on it, and need xs to match on it, and don't need it and can immediately get rid of it. P the Perceus it's true for all cells, this is property called garbage free, that means at one time, all cells will be freed exactly when no longer used.
And of course few other nice optimizations you can do to make the example even more efficient, and however want to talk about one particular optimization, and that's reuse analysis, as you can see here, let's assume the list xs is unique, and comes in reference count of 1, and drop instruction decrease reference count xs go down to 0 and freed.
Immediately after we allocate new cons cell, his seems kind of wasteful, that we are freeing ourselves, and then allocating a sell off the same size. .
So what we do is instead install calorie use. If it happens to be unique, and if so it saves the cell as the reuse token, R, or writes null if not unique. So if null... or reverse, actually the cell we rewrite we already have. And it turns out that this can be a surprisingly effective optimization that can often, at least in some benchmarks make gigantic difference in perperformanceperformance. However in this work, we found that it is not quite so simple, and we show several examples how reuse analysis that have like analyses that have been implemented in the past fall short. So take for example, we pass to map function, and allocate new concept, and other previous reimplementation state is that they would see, we have cons, Let's try to drop reuse access so that we can use it for the new cons cell. And in a way this is pretty good because we know have a chance to reuse xs for this in itself but in a way it's also not good, because we need to make sure that xs still live. And in particularly, that means the xs we pass down to map will not be unique, and no resues can take place in the recursive call. And that means that map can no longer update to xs and list and place, so we might have lost quite a lot of reuse opportunities, because map can reuse for each cell of the list of benefit of just having one extra reuse.
And even worse now hold on to xs, during recursive call, and doubleded our memory usage from baseline, of Perceus because we have xs and ys memory at the same time.
We have defined new reuse analysis, drop-guided reuse, that does not suffer from the problem, the guidal principle here, uided reuse analysis should not prevent ownership from being passed. That means in particular we want to only reuse dead value. And to achieve this Unlike previous reuse analysis, which usually would insert the proper use calls before inserting the reference count instructions. We now insert the drop reuse called after the reference count instruction after the Percius person algorithm has run.
Then it is particularly simple because that roll is exactly the values that will be dropped, and we can just be right, a drop into a drop reuse, where we have reuse opportunity, in particular this will avoid the problem from the last slide, and simplified the analysis, and made much less fragile.
However, we still had a bit of a problem with this, because the Percius algorithm is garbage free, will never hold on to cell longer than need to. But this is not true of previous reuse analysis, and it's also not true of our ... normally would drop xs and free xs, before recoversor recursive call. We can rewrite the drop into a drop reuse and hold on to the cell x s potentially as a reuse token.
R, and we'll hold on to it here at the drop reuse call, then do the recursive call to map, and then use it in the cons o in particular, are will suddenly stay live during this recursive call. And suddenly have this garbage in memory.
However, impeericly we found this is pretty good opportunity, this is optimization you should do, and turns out KWIE efficient for map functions we needed a better memory bound to precisely say how our automatic analysis here changes space usage of program. And we call this new memory bound frame limiters. The intuition is as follows. We have a small number of reuse cells and each function, which we can treat as a constant . Might be kept alive as we seen during the recursive call. So the example, number of recursive calls that we have times the size of cons cell, or in general, it will be frame limited, in the sense of this limited by a constant times the number of stack frames that we have at any given point in journeys around him off program.
So how can we actually reason about this and how can we prove particularly results actually frame limited. To do this we simplified the main Linear Resource calculus of Percings ius work. And made it easier to reason about when it's evaluated. And able to introduce just single stack condition, in order to be able to reason about space usage, and not only about when things go out of scope, and also, about exactly the extra space a program will need.
I'll give you one example of this calculus so you get a taste of it. Have here borrowed environment, variables which are not going to be referenced. And we have multiset of owned variables, that are reference counted. And in particular, this is linear environment, that means, if you take a look at the variable, here only consumed variable X, so linear environment only consist of X, but unlike normal linear logic, we can remove it from our context. PS we insert a specific drop instruction that decrement the reference count.
And we know when we take a look at the left construction, here we can have the stock condition to further reason about space usage on the lateral normally in the neurologic what you would do is that you split the context in to two parts, and then gamma 2 to compile E2.
And we can use the star condition to say presisly splitting. If we leave it unrestricted, certainly have sound calculus. And ensure, will at the end of the program, all garbage will be cleaned up.
So no space leaks in that sense. However can introduce the following role, if Y is a variable in gamma 2, needs to be in the free variable of E2.
Which ensures it's actually use in E2 and then recover the notion of garbage free nas. In the which was first introduced in the past this work also in this much, much more simplified copies. And we can use the following rule, where we say a variable can be in gamma to either if it's actually used in the expression. Or example, a typ analysis find out that the size of all of the memory that we can possibly refer to is less than a constant. In particular, reuse tokens.so we have syntaxic condition, condition that can allow us to actually know how like what space behavior, the program will have a contract .
The first step, we'll take an expression e, that was given by the user, and the drop guide instruction, that will yield garbage free program. And do reframe analysis, to turn some drops into drop reuses. And obtain new expression. However we can show that we have done these two accepts we have abTOIN new from E to E prime prime directly in the linear resource calculus, using the frame limited star role. This proves the output, you will relative to the source program, to concludes reuse optimization is not garbage free, and trade off to be made, and think it's better to do the trade off this way.
But it is frame limited and show other examples in the paper..
borrow inference, not frame limited. And... is frame limited in a certain tense, and can read more in the reference paper. To conclude, I want to give you one last example how analysis really shines. We have to find a new insertion algorithm for red black trees, and we start off...which is either red or black, a left child and right child, a key and a value. And we define a zipper of this tree. We of course can turn the zipper back into the a tree using the move up function, and the find, has cells which have exactly the same size as the cells of our original tree, which means that we use analysis can work here to turn the zipper back into the tree which makes us a very cheap function. In particular, ensure the zipper is always U knee, this can always happen. And we do not glance on the way down, and just record whether we went left and right, and use the appropriate zipper to remember this. And again, the free we put in, again, reuse analysis can work. If we find the see is already present in the map just move up and reconstruct the tree from the zipper, if the tree is not Brent, we have to balance, and you can use the cells of the zipper for cell of the tree. In the end this algorithm, if the tree is unique, except the one cell we put in with new key and new value, really indicates the main mum amount possible. We have the benchmark. 4,200,000 elements into the factory. You can see the reuse analysis work better here. And see Koka , OCaml, and Haskell and swift, and C + +.
We have more benchmark, queens benchmark, a constant folding benchmarks and the binary trees benchmark from the benchmark scheme. And we can see and these benchmarks that are reused analysis is never worse than the alternatives analysisand competitive against virtual systems.
Thank you, and I'm ready to take questions. Thank you.
