The first talk of today's session will be presented by Beniamino Accattoli. And it's on the theory... thank you, Sylvia. I have an announcement, if someone needs captions, there is a link on the web page, in accessibility. 
>> I hope you can hear me. 
So this talk as you know is a very minimalist setting, to fix notation. Only 3 constructers and obstructions and applications and only one computational rule, reduction. 
And it ... the rule can be applied even in abstraction.... 
And now, as you probably know, it's minimalist setting, there are no... turring complete, as you probably know. What you may not know. Is there is not even a notion of result. And this talk is more about that. 
And so... if you take a term of the Lambda calculus T, and functional programming. And take it as function applied to arguments. And what is the result of T? 
Intuitive idea is that it's the beta normal formula of T, and when you reduce it everywhere you get the result. 
And so since, you know Turing complete, you represent recursive functions, and notion of undefined, function, that gives result of... on the function. And in this view "undefined" means diverge. And would be very nice, but in Lambda calculus this symlistic view don't work. It doesn't. 
So why doesn't. To formalize the idea, and why it doesn't work, one talk about the question of theory. Theory that includes beta conversion, and take rule, and closed by all context. And this view essentially is telling you all the divergent terms are all representation undefined, so they must be all equated or all collapsed in the question of theory, and if you do that, and call this T of F. And what does it mean inconsistent, all terms get equated. Very easy to see that. 
Now take these two terms. This is coding of pair, of given term T, and have the looping term, and this is another pair, the pair S, the pair containing the term S and Omega. And these arbitrary. And so in this theory equated. And once you done that, T" because of the property, crucial properties of equational theories you can prove T = S, why. Because T by beta reduction, or expansion let's say, equal to that pair applied to the first projection. 
Okay, this is Lambda term that takes two arguments and gives UT first one, which, since diverging subterm is equivalent in this theory, to the other term, applied to the first projection, equivalent to S, so any terms equivalent to this theory, reduction must be included in the equational theory. 
Now this thing not said in most basic courses of Lambda calculus, was by Wadsworth and Barendregt in the 70's, and proposed refine approach identifying. Terms can computing result with solvable terms. Undefined terms are terms that are not solvable, and so called "unsolvable terms ". 
What does this mean in so define solvable term, define context. 
So this is slightly different than ones in textbook but are equivalent, so the context, put the whole everywhere, but right subterm of application. So whole can be just self or abstraction, or left of applications. 
Official definition is term is solvable if there is head context, if you plug that term inside the context, then reduced to identity. Together, when you plug... get identity. I'll explain a bit what does mean. 
But essentially the context can interact with T and fully exhausted solve it somehow. 
And produce what? 
Produce the most basic term, identity. Which is closed. One would say, a variable, but a variable would be open, so identity. And important point collapsing alunsolvable terms, terms that do not satisfy this definition, and represent undefined, is consistent, so doesn't equate all terms. 
Now if you reconsider the terms I given in the previous example, they are solvable. How can you say that? 
Just take these head context which is there. And instead of taking the first projection, you take a term that takes two arguments and gives you identity. And throws away the arguments, and so if you put the first term there, into that head context, you get this, this term here. 
And by reduction, the argument becomes... two arguments, and throw the first one away, and second one, you get identity out of the box. 
And this means that these two terms in this other approach, define meaningful. Using this word, in the literature. 
So what happened here, solvable approach is more meaningful because we have enlarged the set of meaningful terms, not that forms a -- meaningless. Two forms are meaningful, are not the only meaningful terms, there's more. These two terms are not, cannot be normalized, because they have a divergence term and still they are meaningful. In this approach. 
Now, so the point is not where the term is convergent, on contains divergent subterms, solvable terms divergent is present, but removable. Key point, net context. Net context, is the property that you can interact with putting in the whole. But it can not just throw it away. Okay, because the thing you put in the whole can not be an argument, can not be thrown away without interaction. 
Now you may wonder what are unsolvable terms, what do they look like. Typically omega, is unsolvable, because you can give arguments, and it will keep diverging. 
It's divergence is not removable by interaction with the context. 
Okay. And solvability -- you might like or not. That definition of solvability, but many equivalent definition of solvability, and can be characterized in many ways. 
Typically the most famous CHASHG ryization is operational. Where head reDUSHGS means... so never inside the right subterm of application, is this is due to Wadsworth in the 70's, and also many semantical characterization. But most notable one is that a term is solvable if is only if it has nontrivial interpretation in Scott's pragmatic infinite notational model. First model of Lambda calculus, and happens in many other models. 
And it's also true T is solvable if and only if, if it's typeable with intersection types, or with refinement that I like to call multitypes. It's a variant of intersection types, and you will hear more about this in later talks. And actually there is some nice interplay between characterizations shown here by de-Carvalho. With the multitypes you can read the number of head steps, with the reduction, the one that CHASHG rises solvable terms operationally, and read from the multitype derivation, and particularly, closes to the picture, Dal Lago, and myself, is also reasonable time costs model and you'll hear more about in the session. So Barendregt's book in the 80's, solvability notion. Whole book written on this notion. Later on more things relaxed. In sense that people realized you can find other meaning predicates not just solvability. For meaning predicate I mean you have identified terms computing result with terms satisfying predicate P, and undefined terms that don't satisfied. And you have the collapsing all -- all the terms that don't satisfy the predicate give you consistent eq theory. Okay, this is the background, and let's talk about Call-by-Value. 
Plot kins CbV value, better than Church-Scott-Barendregt, strong call by name, today call strong call by name calculus. 
And plot kin setting based on concept of value. And variables. And B-reduction, restricted by value. What does it mean, the argument can only be value. So trigger beta reduction, if the argument is a value. So we call beta-V step. 
Okay. 
Now turns out denotational semanticses and meaning for CbV is less understood than traditional Lambda calculus. 
And first explored by Paolini Ronchi della Rocca in the 90's, and found, that solvability Cbv does not have the same status than in CbN. The key, one of the stumbling point in Plotkin calculus, no operational charac. 
No operational characterization of high value solvability means that there's no strategy that tells you that term is solvable, if and only if that strategy terminates called by name, this role as I said before, it's played by head reduction, and as proof by Wadsworth. And this is due to the fact that Plotkin's evaluation, does not work with open terms. But open terms are essential for the denot of semantics and solvability. If you can't deal with open terms, you can't real deal with modelling compositionality, and substitution. The typical problem is exemplified by this term, which is a variation over delta delta where essentially the interaction between the two delta says blocked by what. 
Here not by value. Because the argument is given by some open subterm, it's not value, never will become one. 
And so in general, this should be -- this argument should be erased, because X does not occur here, but can not be raced because it's not a value and will not become one. So it's unsolvable, contextually equivalent to omega, and it should diverge, and. 
As I told you solvability is about erasing diverge sequence, but Call-by-Value you can not erase whatever you want. Like this term, is solvable in CbN. 
And erases omega and puts identity as we saw before, but not solvable by Call-by-Value. 
Because in Call-by-Value, it's application, and... will never become a value when argument, and can not be erased. 
So these are the reasons by, reasons complex Call-by-Value. 
So introduce variation, called value substitution calculus, and respect to open terms, and admits operational characterization of CbV solvability. And also number of steps is reasonable time cost model. 
And now, lots of things are not understand about Call-by-Value solvability. In particularly there are characterizations built on intersection types, but they all contain mistakes, and all wrong results in the literature, and it's not clear Call-by-Value solvability is a meaning predicate, and it's also not clear what solvability in the value substitution coincides. And so, in the paper, we develop a theory or answer all these questions. The main result is characterization. 
We are multi types and quantitative these we ... and prove also that Call-by-Value solvability in Plotkin calculus, same as VSC, and one of the most important things is not result of ours, that we stress Call-by-Value solvability is not a meaning predicate, not surprisingly, collapsing all the Call-by-Value unsolvable terms induces inconsistent theory. 
This follows from result inside the literature, but nobody ever pointed it out. 
And we also stressed, results already in the literature. And predicate that we called scrutability that was called potential... actually a meaning predicate in Call-by-Value. 
So in this work you get what? 
There is an alternative to Plotkin calculus, value proposition calculus. 
And Call-by-Value solvability in this framework comparable to Call-by-Value call by name vulnerability, that didn't seem to about the case before, but also the two notion, don't play the same role, one meaning predicate and the other one is not, there is typo there. And also semantics, is actually fine, because solvability fails to be predicate, shows that you need final notion, scrutability, so fact actually semantics is more interesting. And this was never pointed out before, that's it. Thank you.
