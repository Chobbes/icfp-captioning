So I'm going to start with kind of a big question. 
Like, what's the most important problem in computer science right now. If you go ask your colleagues and you know you might hear answers like maybe quantum computing or P versus NP or aachievering artificial general intelligence. But if you go back 50 years, the central problem in computer science was programming and programming languages right there was conferences, this is a picture of the famous NATO software engineering conference. Not so diverse, but see people like D... and many others. And the problem they were looking at was how to write software at all. 
And there is a famous quote from Dijkstra: I won't read it. But essentially says, way back when computers were small and wimpy, we thought programming was hard because, well, we had to write this low level code that was very clever because you know computers are very good, but I can hear just got fast, and we discovered it was the smallest of the computers that was the problem, it was just we don't understand the science of programming. And this set off most of the work in our field developing ideas like structured programming and type system and is program logics, and whole methodology how to write software. Amazing things have been achieved. If you think about modern software -- of course still a challenge to write good software. But a lot of the problems struggling with 50 years ago we made great progress on. If you step back the nature of big systems have changed. Nowadays a lot of systems are developed on the cloud and run on phones, no longer in the era running a program that runs sequentially on one machine. A lot of important software runs in the large planetary scale to root systems. With the end of Moore's law. We're seeing the rise of accelerators, things like GPUs and TPUs And increasingly, you know there's more computation and these specialized accelerators and there aren't CPUs and large systems. We still don't really know the program then. And security is another just full stop. You look in the head lineses you see situation where large data sets of sensitive data compromised and stolen by attackers and still don't have a really good methodology for building secure systems. So I would argue the task that the folks at NATO conference were concerned with, how do we raise level of abstraction and build science of programming, we still need to solve those problems today just that the underlying computers have changed. And one common things to all the modern systems is that networks really play a central role. The only way to have plan tear scale distributed system, that talks to dozens of machines and hundreds of machines in the cloud, and communicates data to your phone is because there's really fast networks that connect them. The only way we can have accelerators that are coordinated with the CPU to do big computations is again because of some kind of network locally on a system. But by in LARNL, the way we program networks -- if we can program them at all. Is writing machine code, we don't really have high level abstractions. And we don't have compilers, sitting there mucking with the bits at very low level of abstraction. 
This is more than just a failure to be creative. For many decades the technology the networking industry has given us has been very closed and fixed. 
And I would characterize this as being a sort of bottom up approach to networking. By "bottom up" the network tells you what you can do and you have to write the program given those capabilities. What do I mean? 
Things like you can send a packet maybe between two machines, that's not something can you define yourself, but have to rely on standard bodies like the IDF give you, and have have to rely on distributed protocols, say PGP, which is setting up routes across the network, you have to worry about what vendors like Cisco or Juniper these big network hardware vendor they tell you they can do. And so, if you're a system owner and you're trying to build some big network system, you may have an idea about the kind of network you'd like to support your application, but it's very hard to take that idea and realize it in a practical setting, instead you end up mucking up with all these low level notioneds addresses VLANs, maybe you're tweaking link weights to get the past you want to the network, it's very indirect, very brittle and limited. So the place we like to go, and place we are going is basically flipping this error around. So the program that runs on the laptop I don't start thinking about the kind of disk and memory I have. And organize my data structures to fit that. I tend to start with a programming language like Haskell and wries down the types I want, and compile those down from memory. And same way I want to take the network functionality I want and able to specify in some reasonably high level way and compile down to the infrastructure. This is becoming possible. Several key ingredients, one is the underlying hardware that we use to build network devices like routers has become more programmable. So there's the possibility to customize it to suit particular needs. There's. 
Early stages I argue family of domain specific languages and domain specific abstractions for describing network functionality. And then there's compilers verification tools and so on, but take all this software, and figure out a map it down to the underlying system. I just want to give you a taste of killer applications driving this so far. I want to be clear this isn't the limit of what we can do. But the lowest hanging fruit, or most pressing needs I've driven networking people to think about generalizing networks to become more programmable. The first killer ap, cloud virtualization. 
The idea here, big cloud company and want to get more customers, the customers probably have existing deployment in their own office, or site, and you would like to be able to take that deployment and move it to the cloud. 
And it's pretty easy to take a java program or C programmer and Haskell program and move to cloud VM, acts just like a server you have locally. But there is all this other stuff attached to such an applications including things like specific IP addresses and specific network topologies, and quickly the companies realized if you can build a capability and take a network someone had locally, and emulate it in the cloud, giving the same structure, and same addresses and everything else, and you can ease this transition path to the cloud, so a bunch of work, maybe about 10 years ago, using programmable networks to achieve this kind of network virtualization. Another killer app was traffic engineering, this is old problem in networking and really the goal here is to take a set of network paths that somehow serve all the traffic while minimizing cost and latency and is maximizing robustness And historically, this is done through distributed protocols, and very clever ways of encoding optimization into those treated protocols, but some of the really bigcloud companies again started to have infrastructure that was sufficiently large, that they wanted to actually use mathematical optimization to come up with the perfect solution. 
solution., so having a platform where you can take a constraint sol VER, and come up with the exact paths you want and push those down into the network actually saved them quite a bit of money and let them run their networks much more efficiently, another place there has been quite a renaissance of work explaining variable networks is monitoring. Historically if you want to understand what the network is doing, think of analog of debugger, you have very rudimentariry tools, you can use command line like ping or trace route, or maybe you have some boxes that can sample traffic and then give you reports of, you know, what packets were going across certain links, and from that you can try to piece together what's going on. Well, with a programmable network ou can actually build a proper debugger, you can have every packet, keep track of a log of what happened. Maybe telling you what paths, it took, how much cueing experienced, maybe causal relationships between different flows. And so this can give you a very fine grained picture of what's going on the network, and that can inform other network operations. And then lastly, there's been some interest I would say this is a little more preliminary in what you might call in network computing. And this is really rethinking the fundamental contract between sort of end host applications and the network. In the internet, the basic contract is the internet gives you best effort packet delivery and nothing else. But it's possible, and in some cases it may make sense to build richer services and have the network do cashing of commonly accessed data items, and have it implement parts of or all of consensus coordination protocols and helping multiple machine agree on state of system. You could have the network run to failure detector, and so if you have the ability to program the network you can do, you know, some or all of these things, and there's a community that starting to explore this. So that's a taste of where the networking field is going. And some of the motivating examples driving them to do that. And want to say about the system architecture level now this change in a little more detail. 
So, let me define a few terms, probably most of you I hope have taken an under grad OS or networking class, and might remember -- actually when I interviewed for postdoc being PL person, my interview question was do you know the different between control plane and data plane, yeah, I remember that and that was it. This is fundamental division of labour in a network. Yeah, Steve. Oh, the slides are not advancing, thanks for noticing. 
So the slides advanced on my laptop, not quite sure how to sync with the room system. 
Hmm... clearly a network failure. 
[Laughter] 
Andre? 
What was the magic move, wave my hand or something? 
Hmm I'm tempted to try to exit full screen, but it's in Slovenia and worried I won't be able to get back in. [Laughter] 






>> NATE FOSTER: Great... okay. 
Still a bit of a lag, but it seems... no... 
Clear 



. 
>> NATE FOSTER: Okay. Let's see... one more check. Seem to be back in sync. Great, I want to tell you a little bit about the underlying architectural changes I'm calling deep programmability, that have made this way of thinking about networks and more flexible and programmable possible. So back to the undergrad networking one of the main... oh, no, I'm going to try to go slowly, so I don't lose my whole time. 
Though, would be very confusing if the slides are a minute behind what I'm saying. 
[Laughter] 




>> NATE FOSTER: Okay. I'll just keep trying until we figure it out. So one of the main divisions of labour in a network that goes back to pretty early network devices and net work architectures is the division between the control plane and data plane, control plane is part of network responsible for running graph algorithms and computing paths and spanning trees, and in some cases enforcing certain kinds of policies and the data plane is the thing that actually forwards packets. So you can think of the control plane, it's really, you know, a general purpose programprogram, and running on CPU, and data plane running on specialized hardware, and it's got some kind of pipeline that can forward packets at very high data rates. 
So this is sort of the at that timus quo that leads, to bottom up design network equipment vendors sell you sort of both of these pieces together the pieces implement standard protocols like IP and BGP and so on, and you it put into the network and as advertised but short of configuring it it's hard to change it's behavior. 
[Off mic]. 
[Laughter]. 
>> NATE FOSTER: It's tempting. 
[Off mic comment] 
>> NATE FOSTER: Wonderful. Yes, I'll keep trying, let me know if I should try and plug in my own laptop, I think the issue is with the room AV system not the display here, let me know if something I should do. First piece was to realize there is no deep reasons these need to go together. , right, network devices have these two roles, the control plane the data plane but they can really be separated. And once you've done that.... 
>> NATE FOSTER: Not quite sure what to do... [off-mic comment]. 
[Laughter] 
>> NATE FOSTER: Very quickly get into the PL material and harder to explain audibleably. And serious question for Andre or room people, something else I should do. Very hard to give a talk with 20 second pause between every animation. I'll just keep going. So once we separate these two, there is... 
no need to have a single control plane attached to every single data plane, and can think about having one control plane managing many data planes, and this... initially was called logical centralization. People said, we can just write centralized algorithms that manage a whole data center or a local network. There's a phrase that I prefer which is it allows you to sort of pick the right unit of abstraction for the control plane. Historically the control plane, always had to be a fully distributed algorithm,algorithm,but with this new kind of architecture, you can imagine having maybe a small number of control planes. Probably want several for fault tolerance, and scale, but don't need 1000 control plane instances for 1000 data plane so you could just have five. We probably want standard ways of communicating between the control plane and data plane, instead of having each vendor implement in some custom way opaque to the outside, we're going to define standard protocols and let anyone implement two sides of it. And then now the control plane doesn't need anything special. It can just be a server running in a rack. Nova Scotia we want to customize the control plane, maybe to implement a different kinds of routing policy, we no onger have to go change BGP or go talk to standards bodies, you can just write a different program running on that server. The last piece and really only happened say 5 or 6 years, the ability to also make the data plane programmable. Now instead of having to implement standard protocol IP or TCP or VLANS, you can actually define custom header formats and custom processing at the data plane level as well. So this term: 
Deep programmability, one we coined in position paper last year. The idea that instead of network infrastructure being fixed and telling you what it can do, truly the network infrastructure has become a fully programmable platform, and program top to bottom, from control plane and data plane, and really end to end, and take the path the packets are taking, and processing. And now think of network has another piece of broader distributed system you might be building, and customize the network behavior to best suit that system. 
So I want to shift now and talk a little bit how we might program this kind of system. 
And I want to tell you a little bit more how the data plane KWIESs workKWIESs -- devices work, We'll come back to this at the end of the talk. But essentially, all data plane devices whether it's a router or a switch or a gateway or firewall, they all have a very similar structure, which is they start by taking packet coming in. Packets are just bits, parse them, and pull out the things the headers might want to examine, and purpose deciding how to forward them, and then do lookups in some fast hardware tables that match on certain header and is maybe look at destination addresses and other pieces of data and do things like forward or drop those packets and after the decisions are made of course we have to deparse the packets back into the bits to send them out. 
So they can be more complicated than this, but the key thing I want you to notice the action of this device is in the middle, with this table, could be many tables, I'm going to pretend just one table, describing the behavior of the device, can be characterized in two phases. 
There's a match phase where we're taking the incoming packets all of them, and deciding how to split them up into different equivalence classes, and then there's the action phase where we can apply small sort of scripts are small procedures to the packets. 
I also want to tell you more about the control plane APIs, this is notional control plane API, but essentially need messages going in both directions to manage the network, we need the network to tell us about certain kind of event switches joining the network or ports coming up or down, and know about statistics, and we may need to know about packets that are in the network that haven't been handled by each device. And then the controller also needs a way to reconfigure the data plane so it has the ability to manipulate the table and is install, delete, and modify rules in the tables and inject packets in the data plane, for example for wants to discover links between two devices that might inject a special probe packet, and it can also request statistics. This is sort of the basics of how the control planes work. So if we want to program these things and apply the same ideas as were done in response to software crisis in the context of networks we want to somehow raise the level of abstraction, and let us think in terms of higher levels things than hardware notions. 
So the kind of built-in model the deep programmable architectures give you really tied to the capability of the underlying hardware, there are these tables and describe how to populate these entries, but limited to single device and have to worry about very low level questions, how do you encode the predicates you want to match on to some linear table or how to split up the processes across entire path to hop by hop actions. 
So probably don't have to convince you, but when I first started looking at this, as functional programmer and someone who thinks about semantics it was immediate obvious much better way to think about this is have domain specific program model and describe the behavior of the network in simple composable abstractions like maybe functions. 
So instead of worrying how they're implemented we can write little functional programs and these things will describe transformations that take in packets and spit out packets and wire them together in interesting ways. 
So let's just explore from first principles what such DSL for higher level functional abstraction for networks might look like. So I'm going to think about functions of this type, going to unpack, and set of packets as outputs. There'll be a set for reasons will become clear in a moment but just for now, you know, one of the things you might need to do is drop packets. So, at a minimum, we need to be able to produce some kind of optional value or the empty set, the common case will be the packets of course just get forwarded, one comes in one goes out, and think of packets as just really records. In general packets can have many different formats for the time being presend packets have one standard type, record with maybe headers encode source and destination addresses, and also throw in location of the packet, which devices it's at, and port it's on the device. As pseudo header that I can work with in the same way.And if you've seen talks on their work before, you might remember that we actually want to keep track of packet histories, I'm going to liv So, the first and most fundamental thing that a network needs to do is to forward packets. , so just to get going I have a primitive, that will let me forward packets, modifying this record. 
So I'm going to have a little primitive for assignment and I can assign the Port field, which will cause the packet on a single device o get forwarded from across the, across the device from one to the next, And even though I'm using assignment here, This is still describing some kind of function on packets. Right I'm modifying these headers or pseudo packet I'm not actually keeping state on the device. . 
Okay, so... now I want to take you through a bunch of other constructs we could have. 
Another component of this kind of language is we probably want to think not about behavior of individual devices and stitch them together and see what happens, we actually want to program whole paths, or the network as a whole. 
And so, we're going to allow ourselves to also program the links, and able to say, when should packets flow across a link from one device to another, and use the arrow notation that denotes program takes packet from switch A and moves them across to switch B. 
There is a lot of cases where we need to apply different policies to different kind of of packets, maybe packets for web traffic on one path, and packets for Zoom traffic to another path, so we want conditionals that can branch on different predicates evaluated against the packet, and then apply one program or another, depending on whether the predicate is satisfied. We also of course want the composition. So we'd like to take a program that describes, maybe forwarding through a part of the network, and another program, and we'd like to stitch those together. 
And there is many different types of that we want. But maybe the most fundamental is sequential composition. You know, doing one thing and then another. And lastly, we also want loops, and this is a little bit counterintuitive because usually networking people don't like having loops if you have a forwarding loop that's a bad situation, with packets cycling around forever and ever. But in many situations, it's useful to be able to describe at least iterated processing in a network. So think about taking maybe one step of processing anything Yeah, do that until packets leave the network. 
That's a very succinct way to describe how to achieve connectivity. 
So putting this all together. 
We. 
Arrive at a little DSL, where we have a set of predicates, simple Boolean predicates and evaluated over the fields in the record that encodes packets and little programming language, where the programs include identity program that does nothing, drop program that produces no packets as output, assignment, composition, and this link construct that forwards from one device to another. . 
And this is quite natural, and some of the early work we did on SDN languages looked like this. 
And little fly in the ointment which is it's actually impossible with the syntax I've shown you here to write a program that produces multiple every packet produces either zero or every program produces either zero or one packets. And so there's never the possibility of doing anything like broadcast or multicast. . So you could imagine adding a special primitive to do this. And in fact some of the early languages I worked on had such a primitive, maybe there is a primitive flood, and if a packet comes in flood will copy that packet N times, where N equals the number of other ports on the device and then it will forward one copy of the packet of each of those ports. And this is maybe a sensible thing to do, but there's a little puzzle is, sorry, font corrupted with the presentation, little puzzle is, you know what happens when with itself. 
So does that somehow produce n squared packets do we somehow deduplicate things. And I don't think these problems are insurmountable but it suggests that maybe, you know, there's something a little odd going on here. So there is a second take on this DSL, so this is one that we ended up with as being a little bit more natural, and essentially the idea is instead of throwing in big operations like flood that are sensible from operational perspective but a little bit clunky semantically, we're going to try and distill the operations down to simpler and more orthogonal primitives. In particular, we're going to add a union operator, which I'll write with a plus. 
Which duplicates packs, and then applies, one of two programs to each copy and using the senior operator we can encode flood fairly easily. If we know the number of Portland device. And we can apply similar streamlining to other operators. 
So instead of loops we can have iteration, instead of conditionals we can encode that with Union. And we can actually smash together bunch of other operating putting the logical predicates and an or we can conflate those with with sequential composition and union, and derive the trivial programs identity and drop, as trivialial filters true and false. And end up with very minimal listic, that encodes everything we seen in simpler and more orthogonal way. If you haven't seen this before, neat thing is we can align DSL with system called KAT. Combination of a language of Boolean predicates and the language of regular expressions. Dexter was interested in this because he was interested in having nice algebraic models of imperative programming, and we take the same foundation and add this interpretation in terms of packet processing functions and some additional primitives like forwarding on the link, or modifying fields in the header, and weget a system called NetKAT. 
The thing I want you to take away from this if you didn't follow the details is. 
First, you can sort of apply the toolkit of the icfp community. 
Going in with a mindset and designing DSLs where your guide and the design both by the operational considerations in the domain but also by trying to do things in a clean semantic way. Even better if you align with existing mathematical framework, that framework can give you guidance, and tell you what kind of primitives to have and how to interpret certain operations in the case of NetKat. The KAT framework gave us guidance in deciding how to resolve tricky issues like this question of how to do flood, as well as a ready made verification toolkit. So this NetKAT language, I'm not going to show all the details, but studied semantics in different ways. We have additional semantics that looks much like the functional interpretation I was showing you in pictures. We also have an axiomatic semantics. Essentially from NetKat itself. As being a kind of automata. And that's very useful in building implementations. And these three things. The three semantics, all fit together with ice they're telling you that they agree and capture the same thing. 
I want to show you just an application of the language, and how some of the pieces in the semantics can be put to work to solve real problems, and this goes back to the first killer app I showed you for deep programmability, which is virtualization. So I want you to imagine the physical network is thing in gray here. Kind of straightforward tree topology with switches numbered 1-7. And ports in small numbers, you don't have to follow the small details, but curious, those ports are the connect and switches. 
And imagine that I want to take a virtual network. So I want to pretend that this network just has a single device. And the device has outgoing ports that correspond to low ends of the tree. 
So you can imagine a customer say in a cloud network would have one switch they have in their office and want to move this thing to the collude, but the cloud provider will run the network in the tree topology. 
So the task we want to solve is programs written against the virtuevirtual network, here is program in yellow just implements forwarding between the 4 ports and virtual switch as followed by destination addresses and want to realize that in the physical network. 
And so, using our implementation of DSL we can actually do this. So here is little demo of compiler running on that exact program showed on the last side, and what it sits out is set of forwarding tables. 
So the low level, For the physical network that implement the semantics of the virtual program. 
When when laid over the physical network, so just showing you couple of rules for switch 1. 
Root of the tree. And rules highlighted in orange, first 2 say if we receive packets coming in on port 2 and going to host 6 we should send those out port 5. 
And if you look at the other switches they implement the rest of the path. So the thing to notice is, we're getting a very succinct abstraction of this behavior of connectivity between these four hosts, and the compiler is filling in all the details for mapping this to the physical topology and also mapping it down to underlying tables. 
You can read ICFP paper, but essentially it's exploiting some of the semantics that catch and Netcat give us, in particular the this representation of programs as a kind of automata, and it uses that to systematically figure out how to simulate the behavior. Out how to simulate that came from the virtual network down but physical layer, and also how to implement non local transits of data through the physical network. So this is a quick diagram of the automaton for that virtual program laid over the physical network and the compiler that takes all this, and of crunches again. And then spits out the tables. . 
So I'm a little bit short on time because offer technical glitches, but I want to turn now and show you one other example where functional ideas can be used to solve a thorny problem in these deeply programmable networks, and you might have noticed we completely ignored the control plane so far, given a little model how to program the data plane, but of course lots of cases where the control plane is important, it has to monitor network events like switch it is joining and leaving and ports going up and down, and shifts in traffic demand and taking all the information and computing set of forwarding behaviors for the network. 
And that's important. 
And so far the little functional language I showed you based on NetKat it can't do those things, just implement a pure function that forwards packets but doesn't respond to events. 
I want to show you an example to motivate why implying these dynamic changes might be hard. 
And I'm going to use this symlistic topology here, I want you to imagine on the left two classes of traffic. Maybe public traffic coming off the internet, and traffic coming over VPN more trusted. 
And then we have few network devices routers and firewalls and those are sitting in front of two sets of servers, internal servers and external servers, and what we want to achieve is public traffic should not be able to reach the internal server it is, only VPN traffic. 
Get to the internal servers, various ways to do this, fire walls to identify the traffic, and filter and forward correspondingly, one way you can do this is use the routers to classify the VPN traffic and public traffic and configure the firewalls so the public traffic we prevent them from going to the internal servers, and VPN allow them to go everywhere. So simplicity assume that each firewall is either doing this filtering or kind of open and allow anything to pass through. 
So first configuration that implements our policy, VPN traffic routed via fire wall 1, it's open, and let's you talk to any server, and public traffic goes fire walls 2 and 3, and actually doing some work, now imagine you want to shift over to different configuration, VPN traffics goes to fire walls 1, and 2, and public, shunted over just to 3. 
The problem is how do you implement this update? 
We have control plane that decides traffic loads are too high and want to reallocate router and is resources this way, but how to actually implement first configuration to the second, now the problem is if we are not careful, we can end up violating our overall policy, public traffic shouldn't reach the internal servers, even though these two configurations both satisfy. In particular if attacker sends public traffic and gets to the first router and go update the firewalls it might be the first router still sends the public traffic to firewall number 2, but now firewall is open, and can get to the internal servers that is violation of our policy. 
And these kind of problems and network updates are not just academic notion, they happen a lot in practice. Situations where connections broken, and sometimes links overwhelmed because too much traffic going to certain upgrade, you get a transient forwarding loops and network operators have sort of common heuristics they use to avoid these situations, they use things like make before break idea being the kind of set up a new configuration before you tear down the old, but these don't handle all of this tricky situations that a rise in practice. You can read post mortems from large sophisticated companies and find that sometimes the outages they have are actually caused by these kind of updates. So if you step back and not worry about the low level details but just think what's really gone on here. The problem with these naive, or undisciplined network updates, is that packets, which were carefully program maybe with a nice functional model so satisfy certain properties now being computed with multiple programs, old program and new program. So if I have an appropriate like security policy I have for that example, that may not be preserved by an update, if I have a packet that takes some number of steps through the network through the old policy and finish with the suffix from the new policy, who knows that will satisfy the appropriate. 
The appropriate may not be robust. So if we want to avoid the situations we can provide some criterion, call it a consistency guarantee to basically rule out these situations, and one possible candidate for such a guarantee is that when we're updating from a configuration A to configuration B, to configuration B, we want it to be the case that at least every packet that's going through the network sees a consistent version. So it sort of is processed with A function and B function, or some weird mixture of the two. But you can show that, if you have any packet consistent update so anything that satisfies this guarantee, then it's going to preserve every safety property that satisfied by both particular with the bad ratio showed with network and firewalls wouldn't have that behavior, because the attackers packet would either go through the green or the blue. 
And again the key insight here is, instead of staying down at the level of routing tables or individual nodes think about the network as a whole implementing some kind of function and think about the appropriates that function yewed like to apply to each packet, and you may wonder how to actually implement these consistent updates, and there has been cottage industry coming up with efficient ways of doing this. And want to show general algorithm that we came up with in our first paper on this called two phase updates. And the idea is basically to use versions, and a clever two PROUND protocol to do the updates, first we're going to have every packet or tag or version tell us which function it's processed with, and that tag attached when it comes to the network, and ensure we only use that same function all the way through. 
So want to do an update what we do is take all the forwarding rules for all devices and before we install them we post process them and add a check for the version corresponding to the new configuration. 
We then go install all the rules, everywhere in the network, and notice the rules are unreachable, dead code because all the rules check for the new version, so far no packets are carrying that version, then once we know the new versions there we go around the perimeter of the network, and update the rules that allow packets to come into the network, so one by one they get the new version, and some packets still entering with perimeter nodes that have not been updated, and they get the old version, but some packets enter with the new version and they get that behavior. And then, once we have... looking at diameter of the network, and how long queued we can garbage collect. 
So this is a very simple protocol. It's works with any topology in any configuration, it can be done in parallel, mostly operations can be paralyzed, so it's very fast. 
The main downside of course that requires extra memory because you have both versions of the function in the network, and you need to add this tag to a packet. Nevertheless quite an influential way of thinking and deployed in google cloud and their network update system. 
So I'm just about out of time, just want to pull things together and talk a little bit about future-looking work. 
So, I talked a lot about these two pieces, how to apply functional thinking to programming data planes, and certain extent programming control planes, what I have been working on last 5 years is going one level deeper, and looking at lower level and more flexible abstractions for the data plane itself, and a language called P4 proposed in 2014, Dave walker, and... both involved in the initial design, and large open source community working on. 
And what P4 is trying to do is go beyond data plane where you kind of have some standard set of match action tables you can configure. But actually make it truly programmable. So define the format to the packets coming into each router, and define state variables used by packets as they go across the router and is customize the pipeline to suit particularly protocols. 
And in particular P4 like many like many industrial languages is designed by a committee, it does not have a formal spec. It has a kind of English document that defines the semantics that has a large C + + reference compiler. So what we've been doing is trying to bring sort of foundations to this language. By following the footsteps of many people here and defining the language syntax and semantics completely formally. And then starting to build verified implementation that can compile those programs to software implementations and eventually do hardware implementations and prove end to end theorem showing that the P for program has been correctly implemented but the target. . 
Stepping back a little bit the idea of deeply programmable networks had a many places where PL people can be involved. 
Although it's been going on for more than a decade, still a lot of work to be done. The low-level languages still being debated and ironed out, and higher level abstractions, and initial proposals things like NetKat, and intent frameworks for industry term for similar languages. And no standard here, and possibility for lots more good ideas. And what I love working in the space is it's not a place you have to ask for guidance about what's a good solution and bad solution. 
Because there is literally decades of operational networking work that can help you understand what problems are, and what the solution might look like. 
Now, of course sometimes all that operational experience might turk your thinking, but at least set of applications and users that can give you guardrails, and possibility of transitional some ideas into real product and is open source and industry, and highlighted ways of our work and work by others successful transitions. 
NetKat itself not directly use industry products I'm aware of, ut there's a whole bunch of frameworks that have very high level, and I would say functional descriptions of what kind of connectivity you want, and pretty much all of the major SDN control frameworks have these. . 
Network virtualization I showed you, main technology behind the VMware NSX product. That's their main networking control product consistent updates are using Google Cloud, similar techniques are generally in a lot of routers in the drive I think it's to those writers, there's been a big push for network verification which I haven't talked about today. But there's both teams at big companies as well as startups. That are taking precise models of network behavior and starting to be reading about them. That particular Galois, of course, ESP has been developed a silo verification framework based on NetKAT North ere's a growing community of academic users of frameworks like P4. 
Just closed with a couple of open problems. 
I think there's, again, lots of revenue for anyone who wants to work on applied problems and think about kind of programming in this ritual space to get involved. I kind of categorize them and if you kind of brought bullets, . One language design is pretty wide open. Initial work on low level hardware languages, but still lots of other languages we need. And PL people with tools and teas can have a lot of impact here. One area particularly interested in is how we can think about bringing language-based security to networks. So right now, if you think about interacting with a network through, you know, the socket abstraction OS gives you, basically thinking in terms of IP addresses but many situations imagine wanting to understand how much you trust certain endpoint or path of that end point or middle boxes to the end point, so space for what I'm calling chain of trust networks that let us have abstraction not just who we're talking to but how we're talking to them. And many problems with compilers and network data planes have to be fast, and work both in routers and as well on the edge, and accelerators, and good idea and is compilers how you map programs and down on to the accelerators well. And have immense amount of impact, and growing community using web assembly using packet processing, if you are interested in web assembly, you can do work there. And lots of work in verification, a lot of it has focused so far on thinking about readability properties, does my network connect or isolate traffic from each other. But whole richer verification products including connecting to hardware, thinking about things like timing channels, and of course developing program logics to make these all this verification more accessible and industry, there's a lot of focus right now at the edge. So part of this district by maybe financial interests are sort of this emerging platform with lots of computers close to cell towers, or offices close to self driving cars, factores or farms, and big tussle right now trying to figure it out, you know, what are the abstractions for edge computing and edge network. Look like. And again chance to talk to PL folks there. And then there's kind of if you're not interested so much in these different verticals, but when I think about sort of cross cutting issues. There's state dealing with failures, there's incorporate elements and quantitative reasoningand of course machine learning coming to networks too. And if you are the kind of person that likes low level PL work, lots of fun. 
So let me stop there. I want to thank my collaborators on this work. A bunch of I won't name them all, but a bunch of students, mentors, and colleagues. And if you want to find more paper and slides around my website. Thanks. 
