Hello, everyone, this is going to be a talk about stage compilation for two level type theory Y stage compilation,
Writing code generating code good ergonomics and safety guarantees. And there are many examples for the existing infrastructure like this. We have typed template Haskell or the template Haskell, we have C++ templates we have traits macros and generics in rust, and in all of these cases there is a separation between what is the compile time language and what is the runtime language. In all these cases I think points to improve ergonomics and safety guarantees as well. So part of this talk is about how to do better than these systems in certain ways.
And what are motivation for using... one is low-cost, I'm saying low-cost, instead of zero cost. Because, in terms of code size when they are using sage compilation. However, I think in many situations it is get a moderate increase insize, but also get like large increase in performance. And I really like like the usual abstractions, developed in fact functional programming. And I would also like to. ... make the cost of these abstractions lower. And also domain specific languages. And this is quite important, I think most of the large performance gains, come from domain specific insights.
And it's not really feasible to have general purpose optimization in some compiler, that knows all about the insights. So make it possible for programmers to KEECH compilerses, and also, there is inlining and fusion with strong GRARN tees.
I have worked a lot, the writing high performance, Haskell code, and frustrating have fragile infrastructure, for inlining and FUNGS optimizations.
It's much more infrastructure... that for example, fusion happens and goes through. What is two level theory. First the idea was developed by Voevodsky. And idea was to do modular treatment for axioms, and two level type theory. And interestingly here.
The title says applications, but stage compilation is not mentioned at all. All applications... it turns out the system is applicable to two...
so, if punishes ood example for like a cross pollination of very distant fields. So what is the features, so there's an integration of a compact and language in the runtime, language, and there's also guarantee think of code output and also guarantee that staging and by vacillating I mean that in the, in the generated code there are no meta programming features anymore, which are, which live in the in the macro stage. And SUCHTs wide range of runtime and metalanguages. O here we can make a choice so we can make the two languages very similar, but we can also choose to make certain advantages here.
And have independent times, in metalanguage, and object language, so that's what I choose to develop in this paper.
So the setting, and also support the present, staging by evaluation. So this is analogous to normalization by evaluation in the sense that we are evaluating a stage program into a semantic domain, and then we are extracting decoder output from this multi domain. So this talk contains small programming examples, for tutorial example can see the artifact, and implementation of this, and samples, from go, and you can see the paper.
And basic rules, two universes.
And closed under type of... the universe of run it is time types, and you have something, will appear...
If you have some type in... it can not appear in the staging, because it happens to live only in the in the compile time language and during staging it has to disappear at some point.
It has to be consulted away.
Okay. And likewise if you have an inhabitant of some compile time type than that inhabitants value also cannot appear in the staging out put. And all in the same universe. No way to cross universes at all. Only way to cross the two universe is by SPAFK staging operations. So listing, if you have runtime type. And this up arrow A, and means type of metto programs, generating code with type A. So in other systems could be called code of A. And called. So instead of upper, called code, or X. So we have quoting. If you have any runtime value, and any runtime expression, you can quote it, and it's just a metaprogram that immediately returns that expression. And have splicing, so metaprogram that has slices.
Essentiallies f PSns that during staging smarter program will be executed and then decode result will be inserted into, into the output.
And we also have this to definition of inequalities. So quoting and splicing, definition of isomorphism And this is important if you want to do polymorphic and dependently type programming because programs will be only aboutto these two roles. And so And then, informally Staging means we are running or meta programs in s[isplices. And then insert the results in the code output.
Okay, so let's look at some more examples. So we can just do inline definition. In this case, the program consists of just two top level definitions. And we have a meta level definition of two which is just a quotation of a sub zero sub zer.
But here run zero.
So here the definition is just a quoted expression, and when defining the function in the runtime language, I can just use a splice. And then when I do the staging, then only the object level bindings remain.
So in case, only have F.
And I perform the splicing.
Okay. Let's look at the compile-time identity function.
So this ID is an ordinary polymorphic identity function, but here I'm using a notation like for a PI type. So if I have any typing new one, this is just a polymorphic identity, but because I have ... , I can use, use these functions in object level code. So in runtime code as well. So here, this is the identity function for Boolean, but I'm doing the splicing, and I'm calling to this metal halide and function, and I'd have to pass the time. And then I have to pass an expression, and the time that I pass is just the lift of ... So because this is the time, then I can pass a quotation of an expression as the next argument and.
And then the output, I can write alternative function.
That is bit more interesting. I say, I want to RUP run...say that I only want to quantify over the runtime types. However, the quantification itself happens in the compile time language. So this a is more like an expression of a runtime time.
And then, it's still the usual identity function. But because this is a lifting of something, it's more like an expression efforts splice it, and then I have to live with back again.
So this demonstration, we have staging and quotation for as well. So see later example, how this has to be used.
And I probably will skip this.
But the point is that this example is only up to the previous mentioned definition, so here I have this type, but actually expect type of this this form. That says, quotation, mispricing or definition isomorphisms and sorry I also mentioned, I should stronger than anything else. So this is kind of borrowed from the, from the meta notation of splicing. If you do staging here, once again, just. So, here the nothing interesting happen, but if we go to a slightly more complicated example for doing the map function inlining then really hear the need to use abstraction over runtime types, because we want to use runtime lists, and as I mentioned before, the only way to grasp between the different stages, is to use lifting and splicing and quotation. Must be a runtime type as an argument, so we can only observe over time facts like this And if you look at the definition of heritability solenoids properly explained in detail. The point is that now we can use the inline map function and if it goes on staging than what we get is essentially this further zero function And we have inline function into this definition.
And this looks.
Might look a bit noisy with all the quotations and splices, and roughly the level of noise, you have to concern yourself with, using Haskell which is quite noise, but in the system can do strong inference for quotes and splices. So before looking at the inference, to note, we have preservation of types.
So listing of a function, and isomorphic definition.
Here this is notation for dependent paradigm is isomorphic to a dependent pair of things.
And we can use these properties, and use bidirectional elaboration, and also the fact we stayed in universes. We do not have the template haske, l.
So here, we can use bidirectal elaboration, and subTIEBing for all the splices, and in the can just become like this. And also implement the artifact demo.
And we can also stage types.
So if incomplete have a natural number. I can by inductionen otheothe almost I'm using.
And you can see that what happens here is that I'm computing Tuple of certain length. How much time do I have 3 minutes. Okay. So, in I lose induction on compile time data, I can compute times, and also use dependentment elimination.
On dependancy types programs, of computed times, and in this case, to define mapping function, have to use DPEMENTent types Northrth stage compilation are quite compelling because one of the one of the use cases one of the important use cases in staging is generic programming.
And although in like normal programming, we can get by without dependent types in generic programming. It's quite common that you really need dependent types, to make a generic program. Okay, so more things, in the artifact, there is implementation stage for the PUGS. And therapeutic fusion type staged SDLC interpreter, and also demonstration of monadic let insertion. And in the paper, that's the formal so in the paper staging these evaluation of level type theory in propitiates over the object theory syntax and correctness of staging is a content activity property and correctness is shown by proof read ontological relations internally to....
Thank you.
