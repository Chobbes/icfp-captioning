So let's start with the very simple question. What is enumeration? And such a simple question deserves a very simple answer, and what we can say is it's a list for Booleans. This is true and false. And the enumeration for natural numbers contains zero, suc zero, and so on.
And at some point the conclusion we have to draw is that this sucks.
And is there some automation we can apply here, and that's what this paper is all about.
So to take a step back and set the stage a little bit, formal verification is great, but it's very expensive, this is one of the lightweight methods that we can use to catch errors early on in the process to reduce this cost.
But the key challenge of this approach is to find the test data to instantiate these properties with. And what we do in this paper is we use a generic approach to exhaustive enumeration of these test values, and what this gets us is a uniform enumeration of the inhabitants of algebraic data types and indexed families, and we can write some generic proofs that establish some notion of correctness for these generic enumerators.
Right, so let's dive in to the meat and potatoes of this talk, what is an enumerator.
So as we saw in the introduction, the basic idea is that an enumerator is a list, but that doesn't fare so well for infinite data types. Instead we have this enumerator data type that essentially defines one layer of recursion of these enumerators. It has an assumption list A that contains the occurrences and it produces an enumeration of a different type.
And an example of such an enumerator is the enumerator for natural numbers that we can define as follows, which just asks to enumerate the actual numbers we have zero at the head of the list or we map the successor over the re-cursively enumerated values.
And then to extract something usable from such an enumerator we can write the function that iterates these enumerators up to a given depth bound.
There are alternative interpretations of these enumerators, like co-inductors, but I won't go into that during this talk.
So why not define these enumerators directly, you might ask? This is something I would just like to quickly point out for binary trees, for example, you would write the following bounded enumeration to enumerate the infinite data types, but the obvious problem here is, of course, that the number of recursive calls grows exponentially with the depth of the type.
And the current setup avoids that.
So if we say that enumerator is correct, what do we mean by that? There are two things, actually, that we are interested in here. The first one is completeness. We say that an enumerator is complete if all the values of the type that it enumerates will eventually occur at some depth if we iterate over that enumerator, which is captured by this complete paragraph of enumerators. And we have a notion of uniqueness that says that an enumerator for type A is unique if all of the values of type A will occur at most once, and the way we formalize this is if there are two proofs -- that point to a value X in the enumeration, then actually these proofs, they point to the same location.
And then as a final thing, as a marker, I want to say for certain enumerators combinators we establish a notion of fairness that ensures that you don't enumerate one constructor first and only then get to the other constructor, but if you want to know more about that, you should read the paper.
To consider a few examples of these combinators, the simplest ones are empty and pure, which construct enumeration with no values or just list a single value into enumeration.
And then there's these operations which you might recognise as haskal's alternative type class, and we offer a choice between two enumerators. They allow you to map the function or apply the results of one enumerator to the values from another enumerator, and then the final combinator that we use, it's actually my favourite one, is for recursive, and it's just the identity function.
So let's see some examples of this. So yeah, for Booleans, a choice between either true or false, or for natural numbers, a choice between zero or successor applied to a recursive argument, and hopefully that you see theory immediately is there is a very clear correspondence between the structure of these data types and the way that we assemble these enumerators, and this correspondence goes further, because if we sit down and write the uniqueness and completeness proofs for these enumerators, we find that the proof structure also follows the data structure.
And this makes enumerators an obvious candidate for generic programming, meaning that we will define these enumerators by induction of the structure of these types. So a quick note about the setup that we have to use here. Obviously an -- value cannot pattern match on a type directly, so usually how these things are done is by creating some data type whose inhabitants correspond to Agda types, which is usually called the universe.
And this is something we can inspect, and then you write a reflection function that reflects this syntactic elements back into Agda sets, and then the enumerator writes such a description, and it enumerates into the semantic description of these.
I won't show the definition of the descriptions here, but it contains sort of the standard combinators for empty unit types and is -- on the products and co-products, and you can have -- recurrences.
And then once we have this setup fleshed out, then actually the generic enumerator is a very direct correspondence between the different constructors of this universe of types and the different combinators that I just showed you.
This is just a direct mapping and for sums and products it's also very straightforward. Please don't try to parse this, but try to appreciate the visual correspondence that hopefully is clear.
So now that we have this generic enumerator, how do we go about proving its correctness? Recall that completeness, for completeness we need to show that iterating produces every value eventually, and uniqueness then we need to show that iterating produces every value at most once.
And as it turns out, to prove these things, we have to show lemmas that mimic the introduction and elimination rule from propositional logic, and there's a brief example of that here.
So this is all nice and good, but then the question is how do we move to indexed families? So the idea here is that this recursive argument that we had in the definition of enumerators, that we can lift that to a function from index to list, which gives us this thing, the I enumerator which takes as its first search argument, which stands for the recursive occurrences, takes a function from index to set, and the assumption that it makes is going to be a function from that index to a list of values at that index.
And the way to think about this is that an I enumerator evaluates enumerators at -- but they vary with some index I.
And we can define the exact same combinators for this data type, and the idea is then that the enumerators themselves are defined as functions that computes on the index. So in this way you get a sort of two-tiered lifting of the structure that you define for regular types to the structure of index types.
And here's just a brief example for finite sets, which if the index is zero is empty and otherwise returns a choice, and notice that here we give the smaller index to this recursive combinator.
And to adapt the generic setup to index types, we use a very similar lifting from sets to I to set, and actually the completeness and uniqueness proofs in the index setting are -- they go through using very similar lemmas about the combinators about the use to implement the generic enumerator.
And then finally, so I remarked at the beginning that one of the reasons enumerators are set up this way is that you get a sharing between recursive calls for free, essentially, but that doesn't work so well for index types because the recursive occurrences are now functions, and every time we apply these functions with a new index, they recompute the result.
And in some cases this leads to excessive recomputation of these recursive enumerators. For example, if you have perfect binary trees, where for every node you have two recursive occurrences at the same index, or for bit factors where there is also a lot of sharing of substructures at the same index.
For this we can use generic memorisation technique, by re-using the generic structure that we defined for regular types, and the way this works is that we define a generic try, a co-indetective data structure, whose shape is dpept on the shape of the index of this function that compute the enumerator, and essentially these data structures represent a tabulation of this function, and if you call this function with the same index more than one time, then there will -- the results will be cached.
We have showed that this is equilt to the non-memoising enumerators, and under certain specific circumstances you get a performance gain if you enumerate index data types, which is critical, I think.
And then in conclusion, just to wrap up, if you need to take away a few things from this talk, it's going to be that you can define generic enumerators in terms of these very natural enumerator combinators. That the generic proofs follow from similar natural introduction and elimination lemmas for these combinators. This approach works for both algebraic data types and index data types, and we can even define generic memoisation on the index if this index is given by a regular description.
Thank you.
