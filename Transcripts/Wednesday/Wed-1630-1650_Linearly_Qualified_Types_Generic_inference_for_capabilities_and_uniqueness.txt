So first off I have to say this article we're talking about is part of the linear Haskell project, which, despite the name isn't really about Haskell, it's much more about the linear part. It's Haskell because we have to choose a language where we do the things, if only because I value my sanity.
Usually in my first slide I put picture of all the people that worked on the project, and quite a lot now, and I kind of gave up.
So instead I put a little timeline. And today for scale.
So what's linear Haskell. The goal of linear Haskell is to add linear types, and we made a lot of progress, to Haskell, or any programming language that already exists in a certain sense. So we're focusing on Haskell. So I'm not going to mention any other programming languages. I'm sure it works in any.
So to explain for a second what a linear type is, the idea is to add an extra function type.
There is a number of ways to do that, that more or less equivalent and have pros and cons. The way we done that in Linear Haskell, is just add a new arrow, which we write percent-one-arrow.
And a function of type A %1 -> B promises that it uses its argument only once. We really say: if the result is consumed exactly once, then the argument result is also consumed exactly once.
And, Arnaud you would say, why do you need something like this.
Why would anybody need something like this. Well, hypothetical audience member, that's an excellent question.
The thing is producing a value, a linear function from A to B doesn't buy you a lot. It's just, okay, made a promise, but it's not really useful to make that promise. What is useful is to require linear function from A to B. Because it let's you constrain how you API is consumed. You can, for instance, force some resources to be used in single-threaded fashion. And once you force single threading, then you can do all sorts of thing.
Like allocating data with malloc directly, bypassing GC and still be memory safe. I'm not going to quite do that today, because it's a bit involved for slides. So we're going to do simpler version to have mutable data structure, so I'm going to pop up some code for mutable array.
What's interesting about that is, not only you have a mutable array, you have a pure interface. So really what I'm saying is I have a data structure that is pure array, but under the hood, I'm going to implement that mutation; because presumably that is much more efficient. Possibly, it really depends on what you're doing. You give up sharing, though, so it's not free. But that's not the point I'm getting at.
What I'm getting at is: the code on the right is really ugly.
And if you look at the code on the left, that's written in the Mezzo language, another Sigplan-friendly language, it's exactly what I would have written naturally. Here we write swap, which just exchanges two positions in an array. All the examples in this talk are extremely contrived because... slides.
But... yeah. I'm a bit jealous.
On the one hand it's understandable, Mezzo is language that's bespoke to speak about mutation of data structures, including arrays, and has a dedicated type system. And I have this general-purpose mechanism, a single type constructor that I've added to the language in which I encoded the thing. So you would expect some degree of boilerplate.
On the other hand... jealous.
If you noticed, by the way, the syntax highlighter, I named the arrays of a "as", and it decided to parse that as the keyword "as", which doesn't exist in Haskell, first it's very funny and second it highlights how ugly the code on the right is. And how many times I wrote "as". Granted I made the effort to make it look as silly as possible with the prime signs. But the general idea is: I named the same array 4 times. We're accustomed as a pure functional programmers to return a new data structure when we modify it. But in that case we even need to return a a data structure when we read it. So considering this, this is just not very nice.
Like, half the code here is renaming the array. Not half the code, but significant proportion. It obscures the idea, and makes the experience not very pleasant. And so my users -- that's you by the way -- are not going to use that. And honestly, just figuring out something is single threaded is something that any computer can do. Doesn't need me to me to tell it "yeah, yeah, because it's a prime and not a".
So I wanted better.
There was, by the way, four other authors by the paper, I don't mean to represent their motivation, everyone has their own, that was mine. It runs a bit deeper than this. But today, we'll focus on that. And if you want to know more, come and see me tomorrow.
The important point, and Frank did a lot of my job for me, thank you.
Is how does GHC handles implicit things. And how do I make GHC do work for me.
So I'm going to clean up this so these things are called constraint they appear both in in the type inference algorithm and also in terms, which is going to be our point. Just clean it up so that we can see. So when I'm doing inference, much like in the previous talk. So GHC walks down the term, says "ok, so I see an application, I want this to be equal to that", or "I see an Eq constraint", like at the top and say "by the way if you call nub you better be able to satisfy the Eq constraint". And in a second phase we solve the constraints with a constraint solver. And on the other hand, every constraint more or less can be manifested to the left of far arrow like this. So I can, as a programmer, even if I don't 100% need to: it can be useful to my API, I can just put a constraint there. And I'm saying when you use this API, you need to do this, but mostly GHC will do this or yell. And that's exactly what we want: we want GHC to tell me "this was single-threaded, I dealt with it" or yell. So the core idea -- I'm getting ahead of myself. Another important point that we will need, is how this fat arrow is implemented. This fat arrow is desugared, ultimately, to a thin arrow, a perfectly normal arrow. So in the intermediate language of GHC, called Core, the "Eq a" thing becomes an argument.
And so... that's where the idea comes from. Let's add a new fat arrow with a percent-one in front, we'll call that a linear fat arrow. And its meaning, is given by the fact that it desugars to a thin linear arrow. So, if I do that -- we need to pull that off, but give me a minute -- then I can write code, with some linear constraints in it. Let GHC infer what I need.
And the meaning of this is just given by the linear arrow. So you don't really need to add any real power to GHC. Except to tell GHC, "you can infer that". So the type of set doesn't fit the slide. I tried to to make it smaller but then it became really small. That being said this slide's so big that I probably could have pulled it off, I realized that this morning. So I wrote set, and you can write code for swap, it's the same function, and now, there is boilerplate, but not silly boilerplate.
Something you notice, there is single "as" on the slide. It's really convenient. There is single "as" on the slide, this is not the linear quantity any more. The function doesn't say, I'm going to use a single MArray. So it has a to return a new MArray to pretend, you know...
Instead the only linear quantity that we have is this read-write constraint, which says I can read and write on my array.
And because it's completely implicit, I don't get to see it. I just get an error message if I do something silly. That's what we set out to do at first. But as it happens. ... there was another thing in Linear Haskell that was displeasing users. If I'm allowed to come back to what I said very early on. I said that producing linear function is not very useful, it doesn't buy you much, what you need is require a linear function. So if I am to write a pure mutable array library, I will have to ask for a linear function at some point. And the way it typically happens is, when you create an array you don't return the array, because it would be unconstrained. I don't really have time to go over this. You have to take a function that takes an array as an argument, consumes it linearly and return something that is not linear, that's what the "Ur" thing means.
Yeah do you like that? Most people don't. It's not as bad as it looks, in a way. Because you will have to kind of scope any resource to say "the resource exists in this scope". That's why I call that a scope function. Why not have the scope be de limited by a function. But the thing is does really cause problems. I gave an example here, very tiny, ugly, but it does cause problem down the line, especially when you want to create several arrays, and you want them to interact. It's quite messy.
I forgot, there's an issue in the linear-base library that I wanted to link, I'll add it after the talk. The slides are online by the way, but I haven't given you the address yet. Don't go to your computer quite now.
Clear.
>> So it caused a lot of problem, and not pleasant, and not the way people want to look at newArray. And a lot of people so far that have designed linear APIs has gotten this wrong at least once. They'd written a newArray-type function in direct style, and the API was not safe.
So at the very least it's not intuitive. So enter the Linearly constrained. It's a bit of a magical constraint, it's harder to implement the Linearly constraint than just linear constraints in general. It's just a special constraint that has some properties because it needs to support contraction and weakening to be completely useful. But then you say okay, I'm creating a new array, Linearly, and just say that. Now the type fits the slide. I think it fit before and it was a bit too big. It looks okay.
And then, I wrote the fromList function in the direct style, which is we want to write for fromList, but also this is not the right type for formList. I said all the examples were really contrived: that's the best example of examples being contrived.
And so how do you pull that off?
Because so far it was wishful thinking. Turns out, it's not that hard. So you can design a declarative system with constraints. The system is close enough to vanilla linear Haskell without constraints so that desugaring becomes obvious. You elaborate that with a constraint generation algorithm. There's a few things to think about because of linearity. You solve the constraints. Some people have already done that: making constraint solvers for this language, they just didn't know. I'm very glad that they did the work for me. And for the rest, you will have to read the paper, there is 15 pages of technical developments so, it goes into more detail. Until then, can you follow Tweag's blog where I blog about the subject from time to time. And here are the slides and QR code also brings you there.
