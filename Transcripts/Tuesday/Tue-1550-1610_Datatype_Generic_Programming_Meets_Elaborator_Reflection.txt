This is joint work and they're here as well. What our work is about is about libraries for dependently typed programming, especially in Agda because that's our favourite language. Usually we have lists in our library and a list say container that has some elements of subtype A. The library can provide this list and data type to be able to point to a particular list and say that satisfies a particular predicatepredicate. We point to the head of the list and say that satisfies P or we use the constructor to say the element is somewhere. Usually in the library we have some associated operations as well. For example, this lookup function that basically extracts the element pointed to and also prove it satisfies P. What's interesting here is that this construction is not specific to lists.
Whenever we have a container like data type, we expect that there is a corresponding anti data type and lookup function.
For example, the library has this data type of bindery trees that has elements stored in their leaves, then we would expect that the library should also provide this tree data type and lookup function. For generic, for general purpose data types such as list and tree we can expect that - well, it is okay to just put everything in the library. We don't have to do anything special, but we often write to our own special stage types and it can be pretty complex. We can't help to find them in the library. A typical example would be an embedded DSL. Here starting from here, we want to extend it to some mysterious language and we are putting well scoped variables, so we need dates of independent cease now, and additional construction such as led expressions and maybe a mysterious construct that is specific to this language and we may use various data type futures such as data type parameters and universe polymorphism. This is what we hope to find in a library, but we still want library support.
For example, here we might want to prove theory about this mysterious element, so we would want the library to give us basically from this definition, we should be able to get this missed any data type and look up function. We want library to give us in. What the library should provide is generic anti construction, that works for all container like data types.
Ideally, the definitions that give us should be something like this and native definition, a definition that looks like what you would have written by hand.
Why do we want niece definitions? When we go along with our development, so here we're proving the subtheorem, that says for any T, if it is well typed, then any mysterious element in it is nice in some way. The first thing we do is try to case split on the missed any argument, so listing all the constructors, and also when we try to find the gold type of hole, the definition look up understanding would show up nicely and those compute nicely.
So that's what we want. We want the libraries to give us generic constructions for deriving native definitions from our own data types. How do we develop such libraries? Since we want native data types and functions, we can use that using Elaborator reflection. The reflection API provides a set of data types representing Agda constructs so we can manipulate agda syntax within agda. This is an example.
We use the constructor to represent the variable in a form of Brian X which can be followed by arguments. We can represent lam expressions, literal and so on and also type expressions.
Here the pi constructor represents a dependent function type and the two arguments are domain dichotomy. Sometimes the API writes type instead of term to informally say that actually mere what we want is a type expression. Perhaps more importantly, the reflection API also provides a type check in to TC and a set of primitive TC computations. So these primitives, we use these primitives to write met aprograms or macros in a form of TC computations and, yeah, then these programs can be run during time checking. For example, we can use the first two primitives declare def and define fun to declare the function and give the definition to the function, and my co-authors have spent quite some time allowing the data types and defining data types as well. It is now in the development version, so you can try it out. What's special about Elaborator reflection is that it provides powerful primitives for that expose some of the functionalitys of the ee Elaborator. For example, we have unify, and there's two terms and solving met avariables appearing in those terms, and we also have this normalized primitive that normalizes term. It turns out to be very useful and we will see that later. Okay. That sounds good, but actually we don't like it because the representations are very imprecisely typed and as a programmer we hate that. So here the example is something like we're trying to write ray type, a pi type a type, a pi type. We might provide the wrong expression and supply an out of bounds index. This makes writing generic constructions using purely Elaborator reflection very difficult and very inappropriate, but there is a solution to this problem, and that is data type genetic programming. I'm not going into the details, but in dpat atype generic programming, you use constructions and proving them correct. Here data D, short for data type descriptions, is a representation of data types and inside we use this data type to represent constructor types.
Let's go back to the example.
Suppose I use ConD to write a function type that has at least one argument, then the argument type, we would use the Sigma construction because of the type of Sigma we definitely had to give a legitimate type as the argument type and later when we need to refer to the argument, we use an ordinary variable of the right type, so everything is under control by the type checker, which is good.
Actually, in our representation we also did something about universal level correctness. So we have a lot of universe levels appearing and we need to satisfy those constraints and we can actually require those constraints to be satisfied because the universe level are internalised so we with can actually reason about them, so that's a plus for Agda. That also looks nice, but still we don't like it. It is because traditionally, and especially in Agda, we were to use this new data type to convert data into types we program with. It looks ugly. I hope no-one is pausing itit. So don't worry about it.
What I want to draw your attention to is that it's actually very inconvenient to use. There's a generic destructor here that has the constructions of your data type.
If you try to case split, you get [indistinct] so long support is gone and you are left with this mess. So what do we do?
Actually, it's kind of obvious.
I mean, we just continue to use data type generic to write constructions, but at the end we don't ewe the new data type. We use ee elaborate cap is reflection to manufacture native data types and functions, so that's kind of simple, that is the basic idea, but if we want to go into some more detail, then suppose that in my library there are two constructions and I want to substantiate the constructions for my own data type myst. Then we need to write some interfacing code. First of all, we need to use a macro genDataD to generate a description of Myst. That's the input to AnyD, but AndD requires more information. It needs to know that MystD corresponds to Myst so it can refer to Myst in it's construction. In connection is as generated by a macro, so it's not a problem. Specifically for AnyD we need more information. We need to tell AnyD where we want to point to.
To specify that, we're giving a proof that MystD is a simple container. You can find the definition in the paper. Now we can invoke AnyD. That's the description of the Myst data type, which we can turn into an actual data type, a native data type by another macro. Usually we can stop here, but if you want to continue to do more, substantiations, then we should establish connection here as well. Felling, look up Any can be substantiated for MystAny.
Actually, I want to talk about this look up any because it is interesting. Look up any come Putins with algebra and it is turned into a native forward function by the macro defined thought. Inside the macro what we do is just write basically a definition like in this. The idea is to use mobilize to expand the definition and get a clean definition for look up MystAny. There is a catch because it doesn't expand unless you replace with actual constructors. So we have to use ee elaborator reflection to do case splitting, and to generate in kind of definition. It is actually not that hard. You can see that is actually very mechanical, so it is manageable.
Finally, we just normalize and you get the clean definition.
One of the questions now would be can we use the generic library now? The answer is, of course not yet. Why is that? We have experimented. We have experimented with some syntax generic [indistinct] kwhee talked about a couple of days ago, but there aren't many and I think we need many generic constructions to be able to call them a library. We need more.
Also we need to extend and refine our framework. We want to support more forms of data types and functions. We want to reduce the effort prior not infer face code because that's a lot. We want to spend more time with the macros because it is difficult to get them right because we simply don't have a very good way to deal with macro correctness at the moment.
Finally, everything is slow right now so some work has to be done. It is a lot of work, but, of course, we appreciate any help we can get, but hopefully eventually we will be able to get to a generic library that the practice al programmer will be happy to use. Thank you very much. 