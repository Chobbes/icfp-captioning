Hi, I'm Simon, , a new technique that you can use to solve your step indexing troubles, this is joint work with Leonard who's sitting overoverin the audience, and Joseph, Ralf, and Lars, and Derek also find them too. So how do you build semantic models with languages with cyclic features.
Could be mixed variance recursive types, and higher order state, and Java mutable objects. What all these language features have in common. Naive semantic models for them, cyclic. And it's not obvious what you do. Right now the dominant choice to build models for the languages is use step and next logic. So the idea is step index, that a natural number either decreases in each iteration, and eventually bottoms out,.
There's just one problem.
Anybody who has done step-indexstep-indexing can attest to.
You do the proof, You have to do a tedious amount of bookkeeping.
I've taken a page from a proof here on the right and I've marked every occurrence of something related to step indexing, it's important you do these things. Because if you get them wrong the proof could be wrong. However, not very interesting things, things like G double, prime is strictly smaller than JJ is less or equal to k minus two and you need to show J w prime is strictly smaller than k minus two. And so ever since the introduction of step-indexing in the early 2000s, there was on going push to simplify step indexing. And this little triangle here, that hides all the natural numbers, and, arithmetic behind the modality inlogic, and how you can use... make sure you didn't mess up the step index. And this brings me to the problem that motivated this work. The later modality is a double-edge sword. On the one hand it's this very powerful tool that logic developers can use to reasonable, recursive constructions soundly and at a high level of abstraction. In various places they can put later R, and, just leaving off the guard would be inconsistent.
However that's not how the users typically think ant the late modality. I don't know about you I'm not typically filled with joys, being saved from inconsistency, all I worry about how to get rid of it. It's a guard and I want to access the contents it's guarding. Let me make this more precise with example that will be the running example in the talk. And predicative invariants in iris.
Used to share state between multiple threads. They could I agree on the invariant R and share it between each other, and each thread can in a single atomic step open the invariant, and get access to the contents of invariance, and get access to R. And then show again, after step R holds. At least that's how this rule is presented on the first page of the first.
Iris paper. With the disclaimer it's simplified for presentation purposes, and what's simplified about it are two things, one is masks, and the other is later modalities. For presentation purposes I'm not going to talk about MAFSHGS in the rest of the talk, but do want to talk about later modality. Impredicative invariants, s the name indicates can store an arbitrary Iris proposition, including other invariants. And as a result their model is cyclic, and the developers of iris, have decided to cut these cycles using step indexing user of the logic doesn't see much of that except for the later modality popping up later in the rule.
And now we come to the tension I mentioned earlier. For user of the logic it's kind of an nuisance, here is a simple example of what you can do in iris, shared invariant, L will store natural number N and want to load from that location. The first step that we do is use invariant opening rule and get the contents of that invariant, guarded by -- what the rule says, the MEEiate next step in the proof is remove the later.
We want to get rid of the the later, because we want to access the contents it's guarding to justify the next step, want to do a load, and only way to do that in separation logic, you have ownership of the location that you want to load from. And how do you do this?
You can't get rid of later modality in general, but there are specific instances you can.
Call the later elimination problem. We have later in our context, but we need R to actually proceed and approve.
And before this work, there were three existing options. That you could use.
The first one is timeless propositions, which are propositions that do not care about step indexing at all, which means you can just remove the later modality in front of them. And maybe your invariant is not entirely timeless but there are tricks that you can use you can use commuting rules to maybe push the later in across, separating conjunctions existential quantifiers and so on, until reach time with parts, you can access those. And finally, there's something called programs steps, which you can use to get ridlater modality, and to do that you need to step the program, and that's how internally step indexing is made sound, and these existing solutions are very useful, they work in most cases. For example for the simple invariant I showed you earlier, they work. The contents of invariant are timeless, and doesn't care about step indexing at all. You can just use them. However the solutions are no silver bullet, there are cases and admittedly they are rare, but they do occur every once in a while, the solutions don't help, a very simple example nested invariant, and we take the original invariant we have, and put inside another invariant, and the contents of that invariant are no longer timeless, what does this mean for your proof, if you now open the outer invariant, we're stuck: it's not timeless, and can't get rid of later modality there. And nothing to commute. And we need to access the points before the next program step, so can't use the stepping rule.
So... what do we do?
Well... you could say that's actually not a useful example Simon, kind of ridiculous, why would you take that invariant and put into another invariant.
To that I would say two things, yes, that example is ridiculous, but characteristic of a problem that does occur in more advance use cases, but too complicated for slide 11 of this talk. And other thing I would say, I was in a situation very similar to this about 3 weeks into the learning Iris and happily nested my invariance, and probably didn't carefully read the documentation I should have read, and pretty much in that situation. So what did I do?
I cried for help.
I went to the Iris help desk, a chat on Iris with loads of very helpful people, and said, I have my invariance like this and now I'm stuck, what do I do. You can do that, unfortunate thing is result you get in these cases is typically frustrating. So someone very clever, nonlocal refactoring of the proof, that sucks because you have to touch a lot of code, that means you flatten entire invariant hierarchy, and maintenance stuff that keeps track of how everything relates and redo everything you already did.
Because the main invariant changed, or no one comes up with something, and you can always give up. A lot of interesting problems that do not involve step indexing, so maybe try one of those.
[Laughter] we looked at this, and well, we didn't like it very much.
So we thought, "can we not develop another option we can use ".
And that's what we did with later credits. Later credits turn the right to eliminate to later. So R into the R, and ownable resource, which denote with little pound sign here.
And that resource, is subject to all the traditional separation logic reasoning, from separation logic.
You can pass them around in preand post conditions, and frame them around function calls and share them be invariance, and rest of the talk I'm going to show you what that looks like. In a nutshell, we take the stepping rule and split into the two parts. One, rule that gives us a later credit after taking a physical step, basically being rewarded for taking that step, and then a second rule that allows us to spend that later credit for later elimination, if you take the rules and put them together you get a rule from above, nothing changed.
But you don't have to use them right after each other. You can use earlier steps of computation, to justify later elimitations down the road, for example, in this case, take a later credit we get in adecision to 41 + 1. And justify, and get the load of location L, specifically we take one step, of computation and get later credit. And now, use the power of separation logic to say, look a function call, and resources don't need them for function call, I want to frame them around the function call. That means after the function call we still have the later credit, and get to the nested invariant, and open it up, and have inner invariant, and can spend that credit to get rid of later modality, and suddenly we just have our invariant we had earlier in the example, and from here on the proof is pretty straightforward.
So this is what we call prepaid reasoning and that's what later credits enable, and looked at this, and thought can we scale this to even more, and one example I want to discuss in the talk is prepaid invariants.
As you might have guessed by now, our life would be a lot simpler if there were no later modalities in that rule. So before this work I went to the experts and asked can't we just remove later modalities and they were like ahhh, I don't think that's sound. Right?
So let's see what happens when we put later credits into invariant, the idea is relatively simple, build a new kind of invariant that stores the contents that we want and the later credit.
And then when we open that invariant, we have the later credit in hand, so we can use it for later elimination. So we get direct access to the contents of that invariant.
And then we need to put one later credit back, that's generated by the next step of computation.
In fact... we can actually generalize the later credit mechanism a little bit to generate more than one later credit first step, and we do get the full rule, where there is no later here, and also don't have to put a credit back after the next step.
And with that, I want to start to rev up. There is more in the paper I didn't cover in the talk, for example, we applied later credits to two large examples, and did logical relation to reordering, including reordering some stateful operations for promise data type, and did logic, atomicity proofs. As a quick side note, logically atomicity is how you prove linearize ability in iris,nd when you do that in iris, it's easy to get in tricky situations, we could simplify those we tackled a challenging counter, and we were able to simplify the notiom of logical atomicity and Iris improve the soundness of the entire mechanism and as I mentioned earlier we develop extensions and also discuss what mean, because you can generate more than one later credit per step. Bbnd with that, I want to conclude as I promised in the beginning, Later credits and the right to limit a later into an honorable resource which is subject to all the traditional separation logic, reasoning, as we've seen in this talk, we can pass them around via pre and post conditions we can across function calls, and can even put them into invariance. If you want to use them, they're now part of Iris by default, and they have already been applied by multiple ongoing projects.
Thank you for your attention, and I'm happy to take any questions you may have.
