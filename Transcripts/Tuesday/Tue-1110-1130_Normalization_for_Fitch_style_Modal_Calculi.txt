>> Hi, I'm from Chalmers, and I have done this work with Carlos and Fabian, and distinguish paper... warm welcome to the community, and let me get to the point. And normalization for Fitch-style normalization.
>> So what I do know here at the least modality is type some properties and operations. And we're going to commit to special class of modalities, specific the necessity modality, and the operations that this modality is equipped with is the so called necessitating rule which says if you ave a closed value versus long term, basically a way of saying you don't have any free variables in your term of type A, and you can box it up as a template boxes. And you also have the so called axiom k which is constantly box are going to squash them together and you get a box result. This is basic foundation we commit to. But not enough. It also depends on the application of interest.
This box, depends how we interpret this box. Many ways to interpret it. One way think of pure value in impure language or secret value in environment of flow control. And dynamic value context... and each of these these applications demand different operations right you don't always want the same kind of operation. For example, just a so called axiom T. Which is basically in our sort of head positions as types interpretation. It's an operation which takes the alue of a box A to A, you don't want it if you want box A to mean secret right this is basically saying leak the secret you don't want that. So it really is the question here is what are the operations that you're interested in, and sometimes you're interested in different things, and mix and match them you end up in different systems and logics and have to study different systems in isolation.
Not necessarily separately, somewhat together but while respecting differences, So today I'm going to talk about these four systems but they may be some beyond the four I'm going to talk about. We're gonna stick to these four, three, and four are basically found by different combinations of these axioms or operations. And going to talk about normalization, today. And why should anybody care about normalization.
And so a fundamental interest in normalization, even if that doesn't sort of appeal to you.
The other way to look at it perhaps, you have big equivalence semantically equivalent complicated terms, and want to crunch it down to one ing canonical representative, so that you can talk about this entire equivalent class using this one canonical representative matters, because instead of dealing with the noisy terms in that you can now look at these little tiny normal forms which are very well behaved, and you can prove a number of useful things using. So in the paper this example hey look you can have a lot of examples, you can look at them.
And so it's about constructs that help you construct and eliminate the model. And we're going to look at specific way of formulating modal calculi, and extend the notionof lock operator, and thought of delimiting operator, so you have typically have a list of variables in your context and also have this lock kind of getting in the way that separating your list into a sub lists. And the fourth system that I mentioned earlier has has a uniform introduction if you have a context with a lock in it. And this is a term of type A, you ... so what is different is the elimination rule. So four systems have four different elimination rules, and each of them have... this is why the lock really comes into the play you use the lock to carefully formulate how the elimination rule should work, before we get to specifics a bit of experiment, look at rules in fronts of us, and think about implementing substitution, when I say substitution, basically what I mean is I'm going to give you a list of terms for the variable in the terms. And I wants you to implement case for unbox, if you look at this what is going on there is a lot of stuff going on, probably looking at this and going "how am I going to implement substitution, have to slice and dice things, and if your brain is going...
hold on to that fear and hopefully will convince you it's a good idea what we're doing.
So... tedious and syntactic reasoning, even if you may do it once. What will end up happening, is you say, okay, I'm happy to do for one system, but then repeat for each and every system of interest, that's the problem, and difficult to mechanize normalization, and to implement normalization algorithms and very difficult to say straightforward induction, you can not do that any more.
Have to sit and do the work yourself, and appears to be ad hoc technical device. It has elegant semantic interpretation and thus intuition, and we're going to do normalization in semantic way, and specific we're going to do this by technical normalization, by evaluation, and this technique has two critical components, right?
And so the first component is evaluator, or interpreter which is function, and takes the terms in language, and to some semantic domain, so open terms, and think of semantic values being function, some kind of function, that takes interpretation of context, and takes what was produced and invert syntax to normal form.
And The trick is of course and how do you how do you actually implement them, but before we get there, just observe here to here to the normalization function. Once you've implemented these two functions, doing all the hard work, normalization function simply falls that just like composing them right so that's the main appeal. But of course the critical question when it comes to implementing what is the semantic domain, what is the interpretation of context, what is the interpretation of the type. And what is this fat arrow that I haven't told you what it is about So this basically is asking the question of lambda calculi more.
So I'm gonna tell you a story in two parts right, the first we're going to sort of demystify what is always, you can identify the so called possible world semantics of this fits all model . And then the moment we've identified that all we gotta do model specification and you end up getting models, and the models, almost free. Right, so that's how the story goes. So the possible semantics is defined, or thought of the following way, so going to interpret our terms in so called frames, so what is a frame, the frame has 3 components, set of nodes, in this case... this W here is basically a set of words, these are the nodes in the graph, and inbetween the worlds you have two kind of relation, RI for intuitionistic accessibility and RM for modal accessibility right. So you have these two kinds of edges between these graphs, right, and how we're going to use these graphs or frames we interpret type box A at the word W, and interpretation -- model success of original work. So this is interpretation. Get around to what exactly the intuition behind this is. The interesting bit of the interpretation of base types and function types and all the other types you typically have remain the same.
Which can be... you can have a look at the paper if you are interested in that. The interesting question here perhaps, what is the interpretation of the curious lock, we interpret the context of other stuff in usual way, products, what do we do about lock, here we revisit the intuition of box. So you think about box of statement about the future, and ignored the, intuitionistic blue relation here because it is a reflexive relation to for the time being we can sort of ignore that. So if you can think of box is a statement of the future, .
If that's the intuition you are going for. It's a statement about the past. It's as if delta lock, holds it is world W and exists, you where delta holds and this is basic intuition that lock is giving us, and this is what we're going to use for interpretation. And delta lock, holds W, it means it holds... going to write this down.
And once we given the interpretation of types, must also give you what this means in terms we set up. And we have to interpret terms in models as well. And it gives us very intuitive way of thinking of the terms, and what happens over there, if you have formula type box A RNGS you can open the portal into the future and can import value of type A in your future world.
And lamda calculus, corresponds to elimination rule. Which says if you have a term of type box A, you open this portal by marking that in the context adding a lock to the context, and then you get the term unbox the of SA this is how it's defined. But of course, you might have seen some extra restrictions. There too just because you're in a future world doesn't mean you shouldn't make any further assumptions that tried this recipe contest yeah you can add, you can, you know you can make further assumptions in this future world if you want to prime sticking around after the lock so that's the justification for one of the unbox elimination rules, the corresponding export tool the national production says, ...
these boxes instruct subordinate proof. You can close it up, and export any formula type A outside as box A and lamda calculus corresponds to introduction rule, term type A, lock in the context, and get a term of box A, and that's the introduction rule for the calculus. And of course the whole point of these portals or strict suboarednate proofs so you don't copy formulas back and forth, defeat the whole purpose of the box, and can not copy things, and restriction, captured by the variable. The variable rule says you may refer to any variables to the right of the latest lock, anything to of the left of the lock, means it's in the past world, so you cannot refer to it That's the idea.
That's the restriction that the variable was baking so enlightened so that's the end of the possible but the part one of this story in line to the semantics that we've set up, what we're looking at now unroll the definition of the of the fat arrow, so basically interpret the term in the function in all worlds you have interpretation of gamma and A, and possible world SPE Manitobaics now, and normalization of course remainses the same, curious question, we defined the possible semantics which can be thought of interface, now have you interface, and want to, instantiate the parameters of this interface so that you can get a claim a normalization algorithm And we know just from existing literature for the simply typed lambda calculus, you can achieve this by instantiating the set of words to context and the intuitionistic accessibility relation to order preserving embeddings, which can also be defined in an equally, it's almost the same way. And now the interesting question here is what is this model accessibility relation. That's the only remaining bit for us to instantiate interface, and evaluation function, given an intuition for how it's implemented but the moment you pick the right model parameter model accessibility relation.
I'm not going to show the implementation here. So what is this relation is the question we're after, to understand this I want to recap rules from before, one introduction rule, and elimb makings rule depends on terms of interest. But look at rules, you see all of them, something interesting going on, all of them are extension, if you look at the context below.
Extension of context above the line with some side constraints all of them have this form, simply going to say context in conclusion is in some relationship with the context in the premises, and going to write this down, the moment you write this down, you have the possible intuition observe that this is basically saying if you have term type box A, and holds gamma and delta... successor of gamma, and arrows orange arrow to Delta, and now you know that a must hold there, just because that's the definition of box here right in model. So how we're going to read the unbox rule. So this basically what this is basically saying is that now you can look at the syntax, that we're dealing with, looking at the relationship between the context and the conclusion contact impairments, and use this to instantiate the model parameter relation, model accessibility. Relation. So, and that's exactly what we're gonna ddo related to delta for this, this is defined as the following. It says, delta can be factored as an extension of gamma with and decide condition which just before we do the exact same thing for the other.
As for system, extension of gamma and reading off the centre out wards the relationship is.
And corresponding accessibility relation. And so what really going on, it's reflexive and trancetive, expected frame conditions in model logic, that's the reason this is all coming together, expect the frame conditions for the axiom info and can do the exact same thing for the other two system, it still works out. And you can implement by instantiating in that way. So far have been talking about the four systems, right. So curious T and 4axiom that gives interface, or some restrictions of it. And interesting to ask questions, what is... there are questions you can ask beyond the specific axioms and operations we studied today, and road ahead exciting, talking about return and join, and what about interactioning modalities. The richer the modalities the more interesting the applications get. If you think, I want these applications if you can let us know, that would be really nice, and work toward the application, so this is what kind of happening next up. To summarize in nutshell the message is the following, normalization, by Fitch-style modal calculi can be achieved constructed NbE models f instances of the possible world semantics avoiding tedious syntactic arguments based on reduction. Nd the possible semantics, isolate all the modal differences to one specific parameter,